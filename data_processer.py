import json
import numpy as np
import pandas as pd
import ruptures as rpt
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from matplotlib.offsetbox import OffsetImage, AnnotationBbox
from scipy.signal import find_peaks
from scipy.signal import savgol_filter
import statsmodels.api as sm
from PIL import Image
import os
from matplotlib.patches import Rectangle
from matplotlib.offsetbox import AnnotationBbox, OffsetImage
from matplotlib.colors import to_rgb, to_hex
from collections import defaultdict
from matplotlib.patches import FancyBboxPatch



def load_json_data(filename):
    """
    è¯»å– JSON æ–‡ä»¶å¹¶è§£ææ•°æ®ã€‚
    
    å‚æ•°:
        filename (str): JSON æ–‡ä»¶çš„è·¯å¾„ã€‚
    
    è¿”å›:
        tuple: åŒ…å«ä»¥ä¸‹æ•°æ®çš„å…ƒç»„ï¼š
            - fps (int): è§†é¢‘çš„å¸§ç‡ï¼Œé»˜è®¤ä¸º 30ã€‚
            - people_counts (list): æ¯ä¸€å¸§æ£€æµ‹åˆ°çš„äººæ•°åˆ—è¡¨ã€‚
            - body_height (list): æ¯ä¸€å¸§æ£€æµ‹åˆ°çš„èº«ä½“é«˜åº¦åˆ—è¡¨ã€‚
            - orientation (list): æ¯ä¸€å¸§æ£€æµ‹åˆ°çš„æ–¹å‘æ•°æ®åˆ—è¡¨ã€‚
            - head_y (list): æ¯ä¸€å¸§æ£€æµ‹åˆ°çš„å¤´éƒ¨ Y åæ ‡åˆ—è¡¨ã€‚
    """
    try:
        # å°è¯•æ‰“å¼€ JSON æ–‡ä»¶å¹¶è§£æå†…å®¹
        with open(filename, "r") as f:
            data = json.load(f)
    except (FileNotFoundError, json.JSONDecodeError):
        # å¤„ç†æ–‡ä»¶ä¸å­˜åœ¨æˆ– JSON è§£æå¤±è´¥çš„æƒ…å†µ
        print(f"é”™è¯¯: æ— æ³•è¯»å– {filename}ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„æˆ–æ ¼å¼ã€‚")
        return 0, [], [], [], [], []
    
    # è§£æ JSON æ•°æ®
    fps = data.get("fps", 30)  # è¯»å– fpsï¼Œé»˜è®¤ä¸º 30
    frames = data.get("frames", [])  # è¯»å–å¸§æ•°æ®åˆ—è¡¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™é»˜è®¤ä¸ºç©ºåˆ—è¡¨
    
    # æå–æ¯ä¸€å¸§çš„æ•°æ®
    people_counts = [frame.get("people_count") for frame in frames]
    body_height = [frame.get("body_height") for frame in frames]  
    orientation = [frame.get("orientation") for frame in frames] 
    head_y = [frame.get("head_y") for frame in frames]
    
    # æ‰“å°è§†é¢‘å¸§ä¿¡æ¯
    print("è§†é¢‘æ€»å…±æœ‰", len(people_counts), "å¸§ï¼Œå¸§ç‡:", fps, "FPS")
    
    # è¿”å›è§£æåçš„æ•°æ®
    return fps, people_counts, body_height, orientation, head_y

def smooth_stable_data(people_counts, orientation, window_size=10, consensus_ratio=0.8):
    """
    å¹³æ»‘æ•°æ®ï¼Œç§»é™¤å™ªéŸ³ï¼Œä½¿ `people_counts` å’Œ `orientation` æ›´ç¨³å®šã€‚
    
    è¯¥æ–¹æ³•ä½¿ç”¨æ»‘åŠ¨çª—å£è®¡ç®—æœ€å¸¸è§å€¼ï¼Œå¹¶åœ¨æ¯”ä¾‹è¾¾åˆ° `consensus_ratio` æ—¶æ›¿æ¢å½“å‰å€¼ï¼Œ
    ä»¥å‡å°‘å™ªå£°çš„å½±å“ï¼Œä½¿æ•°æ®æ›´å¹³æ»‘ã€‚
    
    å‚æ•°:
        people_counts (list[int]): æ¯ä¸€å¸§æ£€æµ‹åˆ°çš„äººæ•°æ•°æ®ã€‚
        orientation (list[str]): æ¯ä¸€å¸§çš„é¢éƒ¨æœå‘ä¿¡æ¯ã€‚
        motion_states (list[str]): æ¯ä¸€å¸§çš„è¿åŠ¨çŠ¶æ€ ('static' æˆ– 'dynamic')ã€‚
        window_size (int): æ»‘åŠ¨çª—å£çš„å¤§å°ï¼Œå†³å®šå¹³æ»‘æ—¶è€ƒè™‘çš„å¸§æ•°ï¼ˆé»˜è®¤ 10ï¼‰ã€‚
        consensus_ratio (float): è®¤å®šæœ€å¸¸è§å€¼çš„æ¯”ä¾‹ï¼Œè‹¥è¾¾åˆ°è¯¥æ¯”ä¾‹åˆ™é‡‡ç”¨æœ€å¸¸è§å€¼ï¼ˆé»˜è®¤ 0.8ï¼‰ã€‚

    è¿”å›:
        tuple: åŒ…å«å¹³æ»‘åçš„æ•°æ®ï¼š
            - filtered_people_counts (list[int]): å¹³æ»‘åçš„äººæ•°æ•°æ®ã€‚
            - filtered_orientation (list[str]): å¹³æ»‘åçš„é¢éƒ¨æœå‘æ•°æ®ã€‚
            - filtered_motion_states (list[str]): å¹³æ»‘åçš„è¿åŠ¨çŠ¶æ€æ•°æ®ã€‚
    """
    
    # å¤åˆ¶åŸå§‹æ•°æ®ï¼Œé¿å…ä¿®æ”¹è¾“å…¥åˆ—è¡¨
    filtered_people_counts = people_counts[:]
    filtered_orientation = orientation[:]

    # éå†æ‰€æœ‰å¸§æ•°æ®
    for i in range(len(people_counts)):
        # å®šä¹‰æ»‘åŠ¨çª—å£çš„èŒƒå›´
        start, end = max(0, i - window_size), min(len(people_counts), i + window_size)

        # è®¡ç®—æ»‘åŠ¨çª—å£å†…çš„æœ€å¸¸è§å€¼
        most_common_people = max(set(people_counts[start:end]), key=people_counts[start:end].count)
        most_common_orientation = max(set(orientation[start:end]), key=orientation[start:end].count)

        # è®¡ç®—æœ€å¸¸è§å€¼çš„å æ¯”
        people_consensus = people_counts[start:end].count(most_common_people) / (end - start)
        orientation_consensus = orientation[start:end].count(most_common_orientation) / (end - start)

        # å¦‚æœæœ€å¸¸è§å€¼çš„æ¯”ä¾‹è¶…è¿‡ `consensus_ratio`ï¼Œåˆ™é‡‡ç”¨å®ƒï¼Œå¦åˆ™ä¿æŒåŸå€¼
        filtered_people_counts[i] = most_common_people if people_consensus >= consensus_ratio else people_counts[i]
        filtered_orientation[i] = most_common_orientation if orientation_consensus >= consensus_ratio else orientation[i]

    return filtered_people_counts, filtered_orientation

def first_orientation_segments(orientation, body_height, head_y, fps):

    orient_segments = []
    current_orient, start_frame = None, None

    # é¢„å¤„ç†ï¼Œå°† None å˜æˆ 'Invalid'
    orientation = ['Invalid' if orientation is None else orient for orient in orientation]

    for i in range(len(body_height)):
        if body_height[i] is None or head_y[i] is None:
            orientation[i] = "Invalid"  # ä¿®æ”¹ orientation

    # éå†æ¯ä¸€å¸§çš„å§¿æ€æ–¹å‘ï¼Œåˆ†å‰²ä¸åŒçš„ç‰‡æ®µ
    for i, orient in enumerate(orientation):
        if current_orient is None:
            current_orient, start_frame = orient, i
        elif orient != current_orient:
            end_frame = i - 1
            duration = end_frame - start_frame + 1
            orient_segments.append({
                "orient": current_orient,
                "start_frame": start_frame,
                "end_frame": end_frame,
                "duration_sec": duration / fps,
                "duration_frames": duration
            })
            current_orient, start_frame = orient, i

    # å¤„ç†æœ€åä¸€ä¸ªç‰‡æ®µ
    if current_orient is not None:
        end_frame = len(orientation) - 1
        duration = end_frame - start_frame + 1
        orient_segments.append({
            "orient": current_orient,
            "start_frame": start_frame,
            "end_frame": end_frame,
            "duration_sec": duration / fps,
            "duration_frames": duration
        })

    return orient_segments

def filter_invalid_orientation_segments(orient_segments, orientation, body_height, head_y, fps=30, min_duration_sec=3, max_duration_sec=90):
    
    min_duration_frames = fps * min_duration_sec
    max_duration_frames = fps * max_duration_sec
    total_frames = len(orientation)
    
    # è®¡ç®—å‰ 10% å’Œå 10% çš„å¸§èŒƒå›´
    first_10_percent = min(int(0.1 * total_frames), max_duration_sec)
    last_10_percent = max(int(0.9 * total_frames), total_frames - max_duration_frames)
    
    # æ‰¾å‡ºæ‰€æœ‰ "Invalid" ç‰‡æ®µ
    long_invalid_segments = []
    first_invalid_in_10_percent = None
    last_invalid_in_90_percent = None

    for segment in orient_segments:
        if segment["orient"] == "Invalid":
            # æ£€æŸ¥æ˜¯å¦è¶…è¿‡ min_duration_frames
            if segment["duration_frames"] > min_duration_frames:
                long_invalid_segments.append(segment)

            # æ£€æŸ¥æ˜¯å¦åœ¨å‰10%
            if segment["end_frame"] < first_10_percent:
                first_invalid_in_10_percent = segment  # æŒç»­æ›´æ–°ï¼Œæ‰¾åˆ°æœ€åä¸€ä¸ª
            # æ£€æŸ¥æ˜¯å¦åœ¨å10%
            elif segment["start_frame"] >= last_10_percent and last_invalid_in_90_percent is None:
                last_invalid_in_90_percent = segment  # ä»…æ‰¾åˆ°ç¬¬ä¸€ä¸ªå°±åœ

    # æ›´æ–° orientation_segments ä½¿å¾—å‰åç‰‡æ®µå˜ä¸º "Invalid"
    new_orient_segments = []
    invalid_mode = False  # è¿™ä¸ªæ ‡å¿—å†³å®šæ˜¯å¦å°†åç»­ç‰‡æ®µè®¾ä¸º "Invalid"

    for segment in orient_segments:
        if first_invalid_in_10_percent and segment["end_frame"] <= first_invalid_in_10_percent["end_frame"]:
            invalid_mode = True  # è§¦å‘ Invalid æ¨¡å¼

        if last_invalid_in_90_percent and segment["start_frame"] >= last_invalid_in_90_percent["start_frame"]:
            invalid_mode = True  # è§¦å‘ Invalid æ¨¡å¼
        
        if invalid_mode:
            # å°†å½“å‰ç‰‡æ®µå˜ä¸º Invalid
            new_segment = segment.copy()
            new_segment["orient"] = "Invalid"
            new_orient_segments.append(new_segment)
        else:
            new_orient_segments.append(segment)


    # 4ï¸âƒ£ åˆ é™¤è¶…è¿‡ 1 ç§’çš„ "Invalid" ç‰‡æ®µ
    frames_to_remove = set()
    for segment in orient_segments:
        if segment["orient"] == "Invalid":
            frames_to_remove.update(range(segment["start_frame"], segment["end_frame"] + 1))
    
    updated_orient_segments = []
    for segment in orient_segments:
        if segment["orient"] == "Invalid" :
            print(f"Deleted Invalid segment: Start {segment['start_frame']}, End {segment['end_frame']}, Duration {segment['duration_frames']} frames ({segment['duration_sec']} sec)")
        else:
            updated_orient_segments.append(segment)  # åªä¿ç•™æœªè¢«åˆ é™¤çš„ç‰‡æ®µ

    frames_to_keep = set(range(total_frames)) - frames_to_remove
    updated_orientation = [orientation[i] for i in frames_to_keep]
    updated_body_height = [body_height[i] for i in frames_to_keep]
    updated_head_y = [head_y[i] for i in frames_to_keep]
    
    if updated_orient_segments:
        new_segments = []
        prev_end_frame = 0
        
        for seg in updated_orient_segments:
            duration = seg["end_frame"] - seg["start_frame"]
            seg["start_frame"] = prev_end_frame
            seg["end_frame"] = prev_end_frame + duration
            prev_end_frame = seg["end_frame"] + 1
            new_segments.append(seg)
        
        updated_orient_segments = new_segments

    return updated_orient_segments, updated_orientation, updated_body_height, updated_head_y
    
def compute_adaptive_threshold(data, method="std", k=2):
    """
    è®¡ç®—æ•°æ®çš„è‡ªé€‚åº”é˜ˆå€¼ï¼Œç”¨äºæ£€æµ‹å¼‚å¸¸å€¼ã€‚

    è¯¥å‡½æ•°æ ¹æ®ä¸åŒçš„ç»Ÿè®¡æ–¹æ³•è®¡ç®—æ•°æ®çš„åŠ¨æ€é˜ˆå€¼ï¼š
    - method="std"  -> ä½¿ç”¨æ ‡å‡†å·®è®¡ç®—é˜ˆå€¼ï¼šthreshold = k * std
    - method="mad"  -> ä½¿ç”¨å¹³å‡ç»å¯¹åå·®ï¼ˆMADï¼‰è®¡ç®—é˜ˆå€¼
    - method="iqr"  -> ä½¿ç”¨ IQRï¼ˆå››åˆ†ä½è·ï¼‰è®¡ç®—é˜ˆå€¼

    å‚æ•°ï¼š
        data (list[float]): éœ€è¦è®¡ç®—é˜ˆå€¼çš„æ•°æ®åˆ—è¡¨ï¼Œä¾‹å¦‚ `body_height`ã€‚
        method (str): é€‰æ‹©è®¡ç®—æ–¹æ³•ï¼Œå¯é€‰å€¼ä¸º 'std', 'mad', 'iqr' (é»˜è®¤ "std")ã€‚
        k (float): ä¹˜æ³•å› å­ï¼Œç”¨äºæ§åˆ¶é˜ˆå€¼çš„çµæ•åº¦ (é»˜è®¤ 2)ã€‚

    è¿”å›ï¼š
        float: è®¡ç®—å‡ºçš„è‡ªé€‚åº”é˜ˆå€¼ã€‚

    å¼‚å¸¸ï¼š
        ValueError: å¦‚æœæä¾›çš„ `method` ä¸æ”¯æŒï¼Œåˆ™æŠ›å‡ºå¼‚å¸¸ã€‚
    """
    
    # å°†æ•°æ®è½¬æ¢ä¸º NumPy æ•°ç»„ï¼Œç¡®ä¿æ”¯æŒæ•°å­¦è®¡ç®—
    data = np.array(data)
    data = np.array([x if x is not None else 0 for x in data])

    if method == "std":
        # ä½¿ç”¨æ ‡å‡†å·®è®¡ç®—é˜ˆå€¼
        threshold = k * np.std(data)
    
    elif method == "mad":
        # è®¡ç®—ä¸­ä½æ•°
        median = np.median(data)
        # è®¡ç®—å¹³å‡ç»å¯¹åå·®ï¼ˆMADï¼‰
        mad = np.median(np.abs(data - median))
        threshold = k * mad

    elif method == "iqr":
        # è®¡ç®—ç¬¬ä¸€å››åˆ†ä½æ•°ï¼ˆQ1ï¼‰å’Œç¬¬ä¸‰å››åˆ†ä½æ•°ï¼ˆQ3ï¼‰
        Q1 = np.percentile(data, 25)
        Q3 = np.percentile(data, 75)
        # è®¡ç®—å››åˆ†ä½è·ï¼ˆIQRï¼‰
        iqr = Q3 - Q1
        threshold = k * iqr

    else:
        # å¦‚æœä¼ å…¥çš„ `method` å‚æ•°ä¸åˆæ³•ï¼Œåˆ™æŠ›å‡ºé”™è¯¯
        raise ValueError("Unsupported method. Choose from ['std', 'mad', 'iqr']")
    
    return threshold

def detect_change_points(data, percentile=95, window_size=3, visualize=False):
    """
    æ£€æµ‹æ—¶é—´åºåˆ—æ•°æ®ä¸­çš„çªå˜ç‚¹ï¼ˆçªå¢æˆ–çªé™ï¼‰ã€‚

    ä¸»è¦é€»è¾‘ï¼š
    1. è®¡ç®—æ•°æ®çš„å˜åŒ–ç‡ï¼ˆå–ç»å¯¹å€¼å·®åˆ†ï¼‰ã€‚
    2. æ ¹æ® `percentile` è®¡ç®—çªå˜é˜ˆå€¼ã€‚
    3. ä½¿ç”¨ `find_peaks` æ–¹æ³•æ£€æµ‹è¶…è¿‡é˜ˆå€¼çš„çªå˜ç‚¹ã€‚
    4. è¿‡æ»¤æ‰çŸ­æš‚çªå˜ç‚¹ï¼Œç¡®ä¿å˜åŒ–åç»´æŒé«˜å€¼ä¸€æ®µæ—¶é—´ã€‚
    5. å¦‚æœ `visualize=True`ï¼Œåˆ™ç»˜åˆ¶å¯è§†åŒ–å›¾è¡¨ã€‚

    å‚æ•°:
        data (array-like): è¾“å…¥çš„æ—¶é—´åºåˆ—æ•°æ® (å¦‚ body_height)ã€‚
        percentile (float): å˜åŒ–ç‚¹çš„é˜ˆå€¼ï¼ˆåˆ†ä½æ•°ï¼‰ï¼Œé»˜è®¤ 95ï¼ˆå–å‰ 5% æœ€å¤§å˜åŒ–ç‚¹ï¼‰ã€‚
        window_size (int): ç”¨äºè¿‡æ»¤çŸ­æš‚çªå˜ç‚¹çš„çª—å£å¤§å°ï¼ˆé»˜è®¤ 3ï¼‰ã€‚
        visualize (bool): æ˜¯å¦å¯è§†åŒ–æ£€æµ‹ç»“æœï¼Œé»˜è®¤ Trueã€‚

    è¿”å›:
        list[int]: å˜åŒ–ç‚¹çš„ç´¢å¼•åˆ—è¡¨ã€‚

    """

    # ç¡®ä¿æ•°æ®æ˜¯ numpy æ•°ç»„
    data = np.array(data, dtype=float)

    # è®¡ç®—å˜åŒ–ç‡ï¼ˆå–ç»å¯¹å€¼çš„å·®åˆ†ï¼‰
    diff = np.abs(np.diff(data))

    # è®¡ç®—çªå˜ç‚¹é˜ˆå€¼ï¼ˆå–å‰ `percentile%` æœ€å¤§å˜åŒ–å€¼ï¼‰
    threshold = np.percentile(diff, percentile)

    # æ£€æµ‹å˜åŒ–ç‚¹ï¼ˆå³°å€¼ç‚¹ï¼‰
    jump_points, _ = find_peaks(diff, height=threshold)

    # è¿‡æ»¤æ‰çŸ­æš‚çªå˜ç‚¹
    change_points = [
        p for p in jump_points if np.mean(data[p:p + window_size]) > np.mean(data) + np.std(data)
    ]

    # å¯è§†åŒ–æ£€æµ‹ç»“æœ
    if visualize:
        plt.figure(figsize=(12, 5))
        plt.plot(data, label="Data", color="blue")
        plt.scatter(change_points, data[change_points], color='red', label="Change Points", zorder=3)
        plt.legend()
        plt.title("Detected Change Points")
        plt.xlabel("Index")
        plt.ylabel("Value")
        plt.show()

    return change_points

def remove_large_height_changes(change_points, orientation_segments, orientation, body_height, head_y, fps=30, max_duration_sec=90):
    """
    å¤„ç† change_pointsï¼Œåˆ é™¤å¼‚å¸¸çªå˜çš„ç‰‡æ®µã€‚

    ä¸»è¦é€»è¾‘ï¼š
    1. **è®¡ç®—è‡ªé€‚åº”é˜ˆå€¼ threshold**ï¼š
       - é€šè¿‡ `compute_adaptive_threshold()` è®¡ç®— body_height çš„é˜ˆå€¼ï¼Œç”¨äºè¯†åˆ«å¼‚å¸¸å˜åŒ–ã€‚
    2. **éå†æ‰€æœ‰ change_points**ï¼š
       - åœ¨ `max_duration_frames` å†…ï¼Œå¯»æ‰¾æœ€åä¸€ä¸ªå˜åŒ–ç‚¹ã€‚
       - è®¡ç®—è¯¥åŒºé—´çš„ body_height å‡å€¼ï¼Œå¹¶ä¸å…¨å±€å‡å€¼æ¯”è¾ƒã€‚
    3. **åˆ¤æ–­æ˜¯å¦åˆ é™¤è¯¥åŒºé—´**ï¼š
       - è‹¥ body_height çš„çªå˜åŒºåŸŸä¸å…¶ä»–åŒºåŸŸçš„å‡å€¼å·®å€¼å¤§äº thresholdï¼Œåˆ™åˆ é™¤è¯¥ç‰‡æ®µã€‚
       - è‹¥è¯¥çªå˜å‘ç”Ÿåœ¨å‰ 10% æˆ–å 10% çš„è§†é¢‘æ—¶é—´ï¼Œåˆ™ç›´æ¥åˆ é™¤å¯¹åº”åŒºåŸŸã€‚
    4. **åŒæ­¥æ›´æ–° orientation_segmentsã€orientationã€body_height å’Œ head_y**ï¼š
       - åˆ é™¤ç›¸å…³å¸§ï¼Œå¹¶é‡æ–°è®¡ç®—æœ‰æ•ˆçš„ç‰‡æ®µç´¢å¼•ã€‚

    å‚æ•°ï¼š
        change_points (list[int]): æ£€æµ‹åˆ°çš„çªå˜ç‚¹ç´¢å¼•ã€‚
        orientation_segments (list[dict]): å§¿æ€ä¿¡æ¯ç‰‡æ®µã€‚
        orientation (list[str]): æ¯å¸§çš„å§¿æ€ä¿¡æ¯ã€‚
        body_height (list[float]): æ¯å¸§çš„èº«ä½“é«˜åº¦æ•°æ®ã€‚
        head_y (list[float]): æ¯å¸§çš„å¤´éƒ¨ Y åæ ‡æ•°æ®ã€‚
        fps (int): è§†é¢‘å¸§ç‡ï¼Œé»˜è®¤ 30ã€‚
        method (str): è®¡ç®— threshold çš„æ–¹æ³• ["std", "mad", "iqr"]ï¼Œé»˜è®¤ "std"ã€‚
        k (float): è®¡ç®— threshold æ—¶çš„ä¹˜æ³•å› å­ï¼Œé»˜è®¤ 2ã€‚
        max_duration_sec (int): çªå˜æœ€å¤§æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤ 90ã€‚

    è¿”å›ï¼š
        tuple:
            - updated_orientation_segments (list[dict]): æ›´æ–°åçš„å§¿æ€ç‰‡æ®µæ•°æ®ã€‚
            - updated_orientation (list[str]): è¿‡æ»¤åçš„å§¿æ€ä¿¡æ¯ã€‚
            - updated_body_height (list[float]): è¿‡æ»¤åçš„èº«ä½“é«˜åº¦æ•°æ®ã€‚
            - updated_head_y (list[float]): è¿‡æ»¤åçš„å¤´éƒ¨ Y è½´æ•°æ®ã€‚
    """

    total_frames = len(body_height)
    max_duration_frames = fps * max_duration_sec

    # è®¡ç®—è‡ªé€‚åº”é˜ˆå€¼ threshold
    threshold = compute_adaptive_threshold(body_height)

    frames_to_remove = set()  # è®°å½•éœ€è¦åˆ é™¤çš„å¸§ç´¢å¼•

    # éå†æ‰€æœ‰çªå˜ç‚¹ï¼Œç¡®å®šéœ€è¦åˆ é™¤çš„ç‰‡æ®µ
    for i, cp in enumerate(change_points):
        # å¯»æ‰¾ max_duration_frames å†…çš„æœ€åä¸€ä¸ªçªå˜ç‚¹
        future_changes = [p for p in change_points if p > cp and p <= cp + max_duration_frames]

        end_idx = max(future_changes) if future_changes else cp  # é€‰å–æœ€åçš„çªå˜ç‚¹
        start_idx = cp  # è®°å½•çªå˜åŒºé—´èµ·ç‚¹

        # è®¡ç®—è¯¥åŒºé—´ body_height çš„å‡å€¼
        region_mean = np.mean(body_height[start_idx:end_idx])

        # è®¡ç®—å…¨å±€ body_height å‡å€¼ï¼ˆæ’é™¤è¯¥åŒºé—´ï¼‰
        other_frames = [i for i in range(total_frames) if i < start_idx or i > end_idx]
        if other_frames:
            other_mean = np.mean([body_height[i] for i in other_frames])
        else:
            other_mean = np.mean(body_height)  # ä»…æœ‰è¯¥åŒºé—´å­˜åœ¨ï¼Œå–å…¨å±€å‡å€¼

        # è®¡ç®— body_height çš„å˜åŒ–å¹…åº¦
        height_diff = abs(region_mean - other_mean)

        # å¤„ç†å‰ 10% å’Œå 10% çš„å˜åŒ–
        has_early_change = any(p <= max_duration_frames for p in [start_idx, end_idx])
        has_late_change = any(p >= total_frames - max_duration_frames for p in [start_idx, end_idx])

        if height_diff > threshold:
            if has_early_change:
                # åˆ é™¤å‰ 10% å†…çš„çªå˜åŒºåŸŸ
                frames_to_remove.update(range(0, end_idx + 1))
            elif has_late_change:
                # åˆ é™¤å 10% å†…çš„çªå˜åŒºåŸŸ
                frames_to_remove.update(range(start_idx, total_frames))
            else:
                # åˆ é™¤è¯¥çªå˜åŒºé—´
                frames_to_remove.update(range(start_idx, end_idx + 1))

    # è¿‡æ»¤ orientation_segmentsï¼Œå¹¶åŒæ­¥åˆ é™¤ç›¸åº”å¸§çš„æ•°æ®
    new_frames_to_remove = frames_to_remove.copy()

    updated_orientation_segments = []
    for seg in orientation_segments:
        # å¦‚æœè¯¥ç‰‡æ®µçš„å¸§è¢«æ ‡è®°ä¸ºåˆ é™¤ï¼Œåˆ™ä¸¢å¼ƒ
        if not any(frame in frames_to_remove for frame in range(seg["start_frame"], seg["end_frame"] + 1)):
            updated_orientation_segments.append(seg)
        else:
            new_frames_to_remove.update(range(seg["start_frame"], seg["end_frame"] + 1))

    # é‡æ–°è®¡ç®—æœ‰æ•ˆå¸§ç´¢å¼•
    frames_to_keep = set(range(total_frames)) - new_frames_to_remove
    updated_orientation = [orientation[i] for i in frames_to_keep]
    updated_body_height = [body_height[i] for i in frames_to_keep]
    updated_head_y = [head_y[i] for i in frames_to_keep]

    # é‡æ–°è®¡ç®— orientation_segmentsï¼Œä½¿ç´¢å¼•ä¿æŒè¿ç»­
    if updated_orientation_segments:
        new_segments = []
        prev_end_frame = 0

        for seg in updated_orientation_segments:
            duration = seg["end_frame"] - seg["start_frame"]
            seg["start_frame"] = prev_end_frame
            seg["end_frame"] = prev_end_frame + duration
            prev_end_frame = seg["end_frame"] + 1
            new_segments.append(seg)

        updated_orientation_segments = new_segments

    return updated_orientation_segments, updated_orientation, updated_body_height, updated_head_y

def merge_alternating_orients(orientation_segments, fps=30, max_swaps=15, min_duration_sec=3):
    """
    åˆå¹¶çŸ­æ—¶äº¤æ›¿çš„å§¿æ€ç‰‡æ®µï¼Œä»¥å‡å°‘æŠ–åŠ¨å’Œè¯¯åˆ¤ã€‚

    ä¸»è¦é€»è¾‘ï¼š
    1. **åˆå¹¶ç›¸é‚»çš„ç›¸åŒå§¿åŠ¿ç‰‡æ®µ**ï¼š
       - å¦‚æœå½“å‰ç‰‡æ®µçš„æ–¹å‘ä¸ä¸Šä¸€ä¸ªç›¸åŒï¼Œåˆ™åˆå¹¶å®ƒä»¬ï¼Œæ›´æ–° `end_frame` å’Œ `duration`ã€‚
    2. **éå†å§¿æ€ç‰‡æ®µï¼Œåˆå¹¶äº¤æ›¿å˜æ¢çš„çŸ­æ—¶ç‰‡æ®µ**ï¼š
       - è®°å½• `swap_count`ï¼Œè·Ÿè¸ªçŸ­æ—¶äº¤æ›¿å‡ºç°çš„æ¬¡æ•°ã€‚
       - å¦‚æœ `swap_count` è¶…è¿‡ `max_swaps`ï¼Œåˆ™åˆå¹¶è¯¥åŒºåŸŸï¼Œå¹¶åˆ›å»ºä¸€ä¸ªæ–°çš„ç‰‡æ®µã€‚
       - å¦åˆ™ï¼Œä¿æŒåŸçŠ¶ï¼Œé˜²æ­¢è¿‡åº¦åˆå¹¶ã€‚
    3. **å¤„ç†æœªè¢«åˆå¹¶çš„ç‰‡æ®µ**ï¼š
       - è¿½åŠ æœ€åä¸€ä¸ªæœªå¤„ç†çš„ç‰‡æ®µï¼Œé˜²æ­¢æ•°æ®ä¸¢å¤±ã€‚

    å‚æ•°ï¼š
        orientation_segments (list[dict]): å§¿æ€ä¿¡æ¯ç‰‡æ®µï¼Œæ¯ä¸ªç‰‡æ®µæ˜¯ä¸€ä¸ªå­—å…¸ã€‚
        fps (int): è§†é¢‘çš„å¸§ç‡ï¼ˆé»˜è®¤ 30ï¼‰ã€‚
        max_swaps (int): å…è®¸çš„æœ€å¤§äº¤æ›¿åˆ‡æ¢æ¬¡æ•°ï¼Œè¶…è¿‡æ­¤å€¼åˆ™è¿›è¡Œåˆå¹¶ï¼ˆé»˜è®¤ 15ï¼‰ã€‚
        min_duration_sec (int): æœ€å°æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œå°äºè¯¥å€¼çš„ç‰‡æ®µå°†è¢«åˆå¹¶ï¼ˆé»˜è®¤ 3 ç§’ï¼‰ã€‚

    è¿”å›ï¼š
        list[dict]: å¤„ç†åçš„ `orientation_segments` ç‰‡æ®µåˆ—è¡¨ã€‚
    """

    # **åˆå¹¶ç›¸é‚»çš„ç›¸åŒå§¿åŠ¿ç‰‡æ®µ**
    merged_segments = []
    for segment in orientation_segments:
        if merged_segments and merged_segments[-1]["orient"] == segment["orient"]:
            # å¦‚æœå½“å‰ç‰‡æ®µä¸ä¸Šä¸€ä¸ªç‰‡æ®µæ–¹å‘ç›¸åŒï¼Œåˆ™åˆå¹¶
            merged_segments[-1]["end_frame"] = segment["end_frame"]
            merged_segments[-1]["duration_sec"] = (merged_segments[-1]["end_frame"] - merged_segments[-1]["start_frame"] + 1) / fps
            merged_segments[-1]["duration_frames"] = merged_segments[-1]["end_frame"] - merged_segments[-1]["start_frame"] + 1
        else:
            merged_segments.append(segment)
    
    # æ›´æ–° `orientation_segments`
    orientation_segments = merged_segments 

    # è®¡ç®—æœ€å°æŒç»­æ—¶é—´ï¼ˆè½¬æ¢ä¸ºå¸§æ•°ï¼‰
    min_duration_frames = fps * min_duration_sec
    result = []
    i = 0  # è¿­ä»£ç´¢å¼•
    
    while i < len(orientation_segments) - 1:
        current_orient = orientation_segments[i]['orient']
        current_frame = orientation_segments[i]['duration_frames']
        if current_frame < min_duration_frames:
            swap_count = 0  # è®°å½•äº¤æ›¿å˜æ¢æ¬¡æ•°
            combined_segments = [orientation_segments[i]]  # å­˜å‚¨å¾…åˆå¹¶ç‰‡æ®µ
            next_orient = orientation_segments[i + 1]['orient']
            next_frame = orientation_segments[i + 1]['duration_frames']
            j = i + 1  # ç”¨äºæ”¶é›†åç»­ç‰‡æ®µçš„ç´¢å¼•
            
            # **å¦‚æœå½“å‰ç‰‡æ®µæ—¶é•¿è¾ƒçŸ­ï¼Œä¸”ä¸‹ä¸€ä¸ªç‰‡æ®µçš„æ–¹å‘ä¸åŒï¼Œåˆ™å°è¯•åˆå¹¶**
            if current_orient != next_orient and next_frame < min_duration_frames:
                combined_segments.append(orientation_segments[j])
                j += 1
                
                # **ç»§ç»­æŸ¥æ‰¾æ›´å¤šçš„çŸ­æ—¶äº¤æ›¿ç‰‡æ®µ**
                while j < len(orientation_segments):
                    third_orient = orientation_segments[j]['orient']
                    third_segment = orientation_segments[j]
                    
                    # **å¦‚æœç¬¬ä¸‰ä¸ªç‰‡æ®µçš„æ–¹å‘å±äº (current_orient, next_orient)ï¼Œä¸”çŸ­æ—¶äº¤æ›¿ï¼Œåˆ™ç»§ç»­åˆå¹¶**
                    if (third_orient in [current_orient, next_orient] and
                        third_orient != combined_segments[-1]['orient'] and
                        third_segment['duration_frames'] < min_duration_frames):
                        swap_count += 1  # è®°å½•äº¤æ›¿åˆ‡æ¢æ¬¡æ•°
                        combined_segments.append(third_segment)
                        j += 1  # ç»§ç»­éå†
                    else:
                        break  # è§„åˆ™è¢«ç ´åï¼Œåœæ­¢åˆå¹¶
                
                # **å¦‚æœäº¤æ›¿åˆ‡æ¢æ¬¡æ•°è¶…è¿‡ `max_swaps`ï¼Œåˆå¹¶è¿™äº›ç‰‡æ®µ**
                if swap_count > max_swaps:
                    if len(current_orient) > len(next_orient):
                        combined_orient = f"{current_orient}-{next_orient}"
                    else: 
                        combined_orient = f"{next_orient}-{current_orient}"  # ç»„åˆæ–¹å‘
                    merged_segment = {
                        'orient': combined_orient,
                        'start_frame': combined_segments[0]['start_frame'],
                        'end_frame': combined_segments[-1]['end_frame'],
                        'duration_sec': sum(seg['duration_sec'] for seg in combined_segments),
                        'duration_frames': sum(seg['duration_frames'] for seg in combined_segments)
                    }
                    result.append(merged_segment)  # å­˜å‚¨åˆå¹¶åçš„ç‰‡æ®µ
                    print(merged_segment)  # æ‰“å°åˆå¹¶ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
                else:
                    result.extend(combined_segments)  # äº¤æ›¿æ¬¡æ•°è¾ƒå°‘ï¼Œä¸åˆå¹¶
                
                # **è·³åˆ°ä¸‹ä¸€ä¸ªæœªå¤„ç†çš„ç‰‡æ®µ**
                i = j  
            else:
                # **å½“å‰ç‰‡æ®µä¸ç¬¦åˆåˆå¹¶æ¡ä»¶ï¼Œç›´æ¥æ·»åŠ åˆ°ç»“æœ**
                result.append(orientation_segments[i])
                i += 1  # ç»§ç»­ä¸»å¾ªç¯éå†
        else:
            # **å½“å‰ç‰‡æ®µä¸ç¬¦åˆåˆå¹¶æ¡ä»¶ï¼Œç›´æ¥æ·»åŠ åˆ°ç»“æœ**
                result.append(orientation_segments[i])
                i += 1  # ç»§ç»­ä¸»å¾ªç¯éå†
    
    # **è¿½åŠ æœ€åä¸€ä¸ª segmentï¼Œå¦‚æœå®ƒæœªè¢«å¤„ç†**
    if i == len(orientation_segments) - 1:
        result.append(orientation_segments[i])
    
    return result

def merge_orientation_segments(orientation_segments, orientation, body_height, head_y, fps=30, min_duration_sec=3, max_duration_sec=15):
    """
    åˆå¹¶çŸ­æ—¶çš„å§¿æ€ç‰‡æ®µï¼Œå»é™¤ä¸ç¨³å®šçš„ç‰‡æ®µï¼Œå¹¶ä¼˜åŒ–æ–¹å‘æ•°æ®ã€‚

    ä¸»è¦é€»è¾‘ï¼š
    1. **åˆå¹¶çŸ­ç‰‡æ®µ**ï¼š
       - å¦‚æœç‰‡æ®µ `duration_frames < min_duration_frames`ï¼Œåˆ™åˆå¹¶åˆ°å‰ä¸€ä¸ªå§¿åŠ¿æ®µï¼Œç›´åˆ°æ‰€æœ‰çŸ­ç‰‡æ®µè¢«åˆå¹¶å®Œæ¯•ã€‚
    2. **åˆå¹¶ç›¸é‚»çš„ç›¸åŒå§¿åŠ¿ç‰‡æ®µ**ï¼š
       - å¦‚æœç›¸é‚»ç‰‡æ®µçš„ `orient` ç›¸åŒï¼Œåˆ™åˆå¹¶ã€‚
    3. **ç§»é™¤æ—¶é•¿å°äº max_duration_sec çš„é¦–å°¾ç‰‡æ®µ**ï¼š
       - å¦‚æœé¦–å°¾ç‰‡æ®µçš„ `duration_frames < max_duration_frames`ï¼Œåˆ™åˆ é™¤è¯¥ç‰‡æ®µçš„å¸§æ•°æ®ã€‚
    4. **è°ƒæ•´çŸ­ç‰‡æ®µçš„å§¿åŠ¿**ï¼š
       - å¦‚æœç‰‡æ®µ `duration_frames < max_duration_frames`ï¼Œå¹¶ä¸”å®ƒçš„å‰åç‰‡æ®µæ–¹å‘ç›¸åŒï¼Œåˆ™è®¾ä¸ºè¯¥æ–¹å‘ï¼Œå¦åˆ™è®¾ä¸ºå‰ä¸€ä¸ªæ–¹å‘ã€‚
    5. **å†æ¬¡åˆå¹¶ç›¸é‚»çš„ç›¸åŒå§¿åŠ¿ç‰‡æ®µ**ï¼š
       - é¿å…å› è°ƒæ•´å§¿åŠ¿åäº§ç”Ÿçš„é‡å¤ç‰‡æ®µã€‚

    å‚æ•°ï¼š
        orientation_segments (list[dict]): å§¿æ€ä¿¡æ¯ç‰‡æ®µï¼Œæ¯ä¸ªç‰‡æ®µæ˜¯ä¸€ä¸ªå­—å…¸ã€‚
        orientation (list[str]): æ¯å¸§çš„å§¿æ€ä¿¡æ¯ã€‚
        body_height (list[float]): æ¯å¸§çš„èº«ä½“é«˜åº¦æ•°æ®ã€‚
        head_y (list[float]): æ¯å¸§çš„å¤´éƒ¨ Y è½´æ•°æ®ã€‚
        fps (int): è§†é¢‘çš„å¸§ç‡ï¼ˆé»˜è®¤ 30ï¼‰ã€‚
        min_duration_sec (int): æœ€å°æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œå°äºè¯¥å€¼çš„ç‰‡æ®µå°†è¢«åˆå¹¶ï¼ˆé»˜è®¤ 3 ç§’ï¼‰ã€‚
        max_duration_sec (int): æœ€å¤§åˆå¹¶æ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œè¶…è¿‡è¯¥å€¼çš„ç‰‡æ®µæ‰ä¼šè¢«ä¿ç•™ï¼ˆé»˜è®¤ 15 ç§’ï¼‰ã€‚

    è¿”å›ï¼š
        tuple:
            - orientation_segments (list[dict]): å¤„ç†åçš„å§¿æ€ç‰‡æ®µã€‚
            - orientation (list[str]): è¿‡æ»¤åçš„å§¿æ€ä¿¡æ¯ã€‚
            - body_height (list[float]): è¿‡æ»¤åçš„èº«ä½“é«˜åº¦æ•°æ®ã€‚
            - head_y (list[float]): è¿‡æ»¤åçš„å¤´éƒ¨ Y è½´æ•°æ®ã€‚
    """

    # **è®¡ç®—å¸§æ•°é˜ˆå€¼**
    min_duration_frames = fps * min_duration_sec
    max_duration_frames = fps * max_duration_sec

    # **ç¬¬ä¸€æ­¥ï¼šåˆå¹¶çŸ­ç‰‡æ®µï¼Œç›´åˆ°æ‰€æœ‰çŸ­ç‰‡æ®µè¢«åˆå¹¶å®Œæ¯•**
    final_segments = orientation_segments[:]
    while True:
        updated_segments = []
        merged = False  # è®°å½•æ˜¯å¦å‘ç”Ÿäº†åˆå¹¶

        for i, segment in enumerate(final_segments):
            if updated_segments and segment["duration_frames"] < min_duration_frames:
                # **å°†çŸ­ç‰‡æ®µåˆå¹¶åˆ°å‰ä¸€ä¸ªå§¿åŠ¿æ®µ**
                updated_segments[-1]["end_frame"] = segment["end_frame"]
                updated_segments[-1]["duration_sec"] = (
                    updated_segments[-1]["end_frame"] - updated_segments[-1]["start_frame"] + 1
                ) / fps
                updated_segments[-1]["duration_frames"] = (
                    updated_segments[-1]["end_frame"] - updated_segments[-1]["start_frame"] + 1
                )
                merged = True  # è®°å½•åˆå¹¶å‘ç”Ÿ
            else:
                updated_segments.append(segment)

        if not merged:
            break  # æ²¡æœ‰å‘ç”Ÿåˆå¹¶ï¼Œè·³å‡ºå¾ªç¯
        
        final_segments = updated_segments
        orientation_segments = final_segments  # æ›´æ–° segments

    # **ç¬¬äºŒæ­¥ï¼šåˆå¹¶ç›¸é‚»çš„ç›¸åŒå§¿åŠ¿ç‰‡æ®µ**
    merged_segments = []
    for segment in orientation_segments:
        if merged_segments and merged_segments[-1]["orient"] == segment["orient"]:
            # **åˆå¹¶ç›¸é‚»ç›¸åŒå§¿åŠ¿ç‰‡æ®µ**
            merged_segments[-1]["end_frame"] = segment["end_frame"]
            merged_segments[-1]["duration_sec"] = (merged_segments[-1]["end_frame"] - merged_segments[-1]["start_frame"] + 1) / fps
            merged_segments[-1]["duration_frames"] = merged_segments[-1]["end_frame"] - merged_segments[-1]["start_frame"] + 1
        else:
            merged_segments.append(segment)
    
    orientation_segments = merged_segments  # æ›´æ–° segments

    frames_to_remove = set()  # è®°å½•è¦åˆ é™¤çš„å¸§

     # ä»å¤´å¼€å§‹éå†
    while orientation_segments:
        first_segment = orientation_segments[0]
        if first_segment['duration_frames'] < max_duration_frames:
            print(f"ğŸ—‘ åˆ é™¤å¤´éƒ¨ç‰‡æ®µ (å°äº {max_duration_sec} ç§’): {first_segment}")
            frames_to_remove.update(range(first_segment['start_frame'], first_segment['end_frame'] + 1))
            orientation_segments.pop(0)
        else:
            break  # é‡åˆ°ç¬¦åˆè¦æ±‚çš„ç‰‡æ®µï¼Œåœæ­¢ä»å¤´éƒ¨éå†

    # ä»å°¾éƒ¨å¼€å§‹éå†
    while orientation_segments:
        last_segment = orientation_segments[-1]
        if last_segment['duration_frames'] < max_duration_frames:
            print(f"ğŸ—‘ åˆ é™¤å°¾éƒ¨ç‰‡æ®µ (å°äº {max_duration_sec} ç§’): {last_segment}")
            frames_to_remove.update(range(last_segment['start_frame'], last_segment['end_frame'] + 1))
            orientation_segments.pop(-1)
        else:
            break  # é‡åˆ°ç¬¦åˆè¦æ±‚çš„ç‰‡æ®µï¼Œåœæ­¢ä»å°¾éƒ¨éå†

     # **ç¬¬å››æ­¥ï¼šåˆ é™¤æœ€åä¸€ä¸ªå°äº max_duration_sec çš„ç‰‡æ®µ**
    if orientation_segments and orientation_segments[-1]["duration_frames"] < 2 * max_duration_frames and orientation_segments[-1]['orient'] == 'neutral':
        last_segment = orientation_segments[-1]
        print(f"ğŸ—‘ åˆ é™¤å°¾éƒ¨ç‰‡æ®µ (å°äº {max_duration_sec} ç§’): {last_segment}")
        frames_to_remove.update(range(last_segment["start_frame"], last_segment["end_frame"] + 1))
        orientation_segments.pop(-1)  # åˆ é™¤ç‰‡æ®µ

    # **ç¬¬äº”æ­¥ï¼šåˆ é™¤ `orientation`ã€`body_height` å’Œ `head_y` ä¸­çš„ç›¸åº”å¸§**
    orientation = [orient for i, orient in enumerate(orientation) if i not in frames_to_remove]
    body_height = [height for i, height in enumerate(body_height) if i not in frames_to_remove]
    head_y = [head_y for i, head_y in enumerate(head_y) if i not in frames_to_remove]

    # **ç¬¬å…­æ­¥ï¼šé‡æ–°è°ƒæ•´ segment ç´¢å¼•**
    if orientation_segments:
        new_segments = []
        prev_end_frame = 0
        
        for seg in orientation_segments:
            duration = seg["end_frame"] - seg["start_frame"]
            seg["start_frame"] = prev_end_frame
            seg["end_frame"] = prev_end_frame + duration
            prev_end_frame = seg["end_frame"] + 1
            new_segments.append(seg)
        
        orientation_segments = new_segments  # æ›´æ–° segments

    # **ç¬¬ä¸ƒæ­¥ï¼šè°ƒæ•´çŸ­ç‰‡æ®µçš„æ–¹å‘**
    for i in range(1, len(orientation_segments) - 1):  # é¿å…è®¿é—®è¶…å‡ºèŒƒå›´
        segment = orientation_segments[i]

        if segment["duration_frames"] < max_duration_frames:
            prev_orient = orientation_segments[i - 1]["orient"]

            # **å¦‚æœå‰åå§¿åŠ¿ç›¸åŒï¼Œåˆ™è®¾ä¸ºè¯¥å§¿åŠ¿ï¼Œå¦åˆ™è®¾ä¸ºå‰ä¸€ä¸ªç‰‡æ®µçš„å§¿åŠ¿**
            segment["orient"] = prev_orient

    # **ç¬¬å…«æ­¥ï¼šå†æ¬¡åˆå¹¶ç›¸é‚»ç›¸åŒå§¿åŠ¿**
    merged_segments = []
    for segment in orientation_segments:
        if merged_segments and merged_segments[-1]["orient"] == segment["orient"]:
            merged_segments[-1]["end_frame"] = segment["end_frame"]
            merged_segments[-1]["duration_sec"] = (merged_segments[-1]["end_frame"] - merged_segments[-1]["start_frame"] + 1) / fps
            merged_segments[-1]["duration_frames"] = merged_segments[-1]["end_frame"] - merged_segments[-1]["start_frame"] + 1
        else:
            merged_segments.append(segment)

    orientation_segments = merged_segments  # æ›´æ–° segments
    
    return orientation_segments, orientation, body_height, head_y

def split_head_y_by_orientation(orientation_segments, head_y):
    """
    æ ¹æ® orientation_segments ä¸­çš„ start_frame å’Œ end_frameï¼Œåˆ†å‰² head_y æ•°æ®ã€‚

    ä¸»è¦é€»è¾‘ï¼š
    1. **éå† orientation_segments**ï¼š
       - æ¯ä¸ªç‰‡æ®µåŒ…å« `start_frame` å’Œ `end_frame`ï¼Œç”¨äºç¡®å®šæ•°æ®åˆ†å‰²èŒƒå›´ã€‚
    2. **æå– head_y ç‰‡æ®µ**ï¼š
       - å– `head_y[start:end+1]`ï¼Œç¡®ä¿ `end_frame` å¯¹åº”çš„å¸§ä¹Ÿè¢«åŒ…å«åœ¨å†…ã€‚
    3. **å­˜å‚¨åˆ†å‰²åçš„ head_y ç‰‡æ®µ**ï¼š
       - å°†åˆ‡ç‰‡ç»“æœå­˜å…¥ `segmented_head_y` åˆ—è¡¨ä¸­ï¼Œä¿æŒç´¢å¼•ä¸€è‡´ã€‚

    å‚æ•°ï¼š
        orientation_segments (list[dict]): å§¿æ€ä¿¡æ¯ç‰‡æ®µï¼Œæ¯ä¸ªç‰‡æ®µåŒ…å« `start_frame` å’Œ `end_frame`ã€‚
        head_y (list[float]): å¤´éƒ¨ Y åæ ‡æ•°æ®åˆ—è¡¨ã€‚

    è¿”å›ï¼š
        list[list[float]]: åˆ†å‰²åçš„ head_y ç‰‡æ®µåˆ—è¡¨ï¼Œæ¯ä¸ªç‰‡æ®µå¯¹åº”ä¸€ä¸ª `orientation_segments` ç‰‡æ®µã€‚
    """

    segmented_head_y = []  # å­˜å‚¨åˆ†å‰²åçš„ head_y ç‰‡æ®µ
    
    for segment in orientation_segments:
        start = segment['start_frame']
        end = segment['end_frame'] + 1  # åŒ…å« `end_frame` æ‰€åœ¨çš„ç´¢å¼•
        head_y_segment = head_y[start:end]  # æå–å¯¹åº”çš„ head_y æ•°æ®
        
        segmented_head_y.append(head_y_segment)

    return segmented_head_y

def process_segmented_head_y(segmented_head_y, frame_window=400, max_timestamps=8, smooth_window=5, max_iterations=10):
    """
    å¤„ç† segmented_head_yï¼Œè¿­ä»£æ£€æµ‹çªå˜ç‚¹ï¼Œåˆ†å‰²æ•°æ®ï¼Œæ¸…ç†æ— æ•ˆæ•°æ®ï¼Œå¹¶å¹³æ»‘æ–­ç‚¹ã€‚

    ä¸»è¦é€»è¾‘ï¼š
    1. **è¿­ä»£å¤„ç†æ•°æ®**ï¼ˆæœ€å¤š `max_iterations` æ¬¡ï¼‰ï¼š
       - é€ä¸ªæ£€æŸ¥ `segmented_head_y`ï¼Œç§»é™¤çŸ­ç‰‡æ®µï¼Œå¹¶æ£€æµ‹çªå˜ç‚¹ã€‚
    2. **æ£€æµ‹å¹¶æ ‡è®°çªå˜ç‚¹**ï¼š
       - è®¡ç®— `threshold` ä½œä¸ºå˜åŒ–æ£€æµ‹æ ‡å‡†ã€‚
       - ä½¿ç”¨ `ruptures` è¿›è¡Œçªå˜ç‚¹æ£€æµ‹ï¼Œè¯†åˆ«æ˜¾è‘—å˜åŒ–åŒºåŸŸã€‚
    3. **å»é™¤æ— æ•ˆæ•°æ®**ï¼š
       - è‹¥çªå˜ç‚¹åœ¨å‰ `frame_window` å¸§æˆ–å `frame_window` å¸§ï¼Œåˆ™æ ‡è®°ä¸ºæ— æ•ˆã€‚
       - å¯¹ç›¸é‚»çªå˜ç‚¹è¿›è¡Œåˆå¹¶ï¼Œå‡å°‘è¯¯åˆ¤ã€‚
       - è‹¥çªå˜ç‚¹æ•°é‡è¶…è¿‡ `max_timestamps`ï¼Œè·³è¿‡è¯¥æ®µæ•°æ®ï¼Œé˜²æ­¢è¯¯åˆ†å‰²ã€‚
    4. **åˆ†å‰²æ•°æ®**ï¼š
       - ä¾æ®çªå˜ç‚¹å¯¹æ•°æ®è¿›è¡Œåˆ†å‰²ï¼Œé¿å…æ•°æ®æ··ä¹±ã€‚
       - è‹¥ç›¸é‚»çªå˜ç‚¹é—´è·è¿‡çŸ­ï¼Œåˆ™è·³è¿‡åˆ†å‰²ï¼Œä»¥é¿å…ç¢ç‰‡åŒ–ã€‚
    5. **å¹³æ»‘æ•°æ®**ï¼š
       - å¯¹äºæ¯ä¸ªåˆ†å‰²ç‰‡æ®µï¼Œä½¿ç”¨ `savgol_filter` è¿›è¡Œå¹³æ»‘ï¼Œä»¥å‡å°‘å™ªå£°ã€‚
    6. **ç»ˆæ­¢æ¡ä»¶**ï¼š
       - è‹¥æ•°æ®åœ¨æŸæ¬¡è¿­ä»£åä¸å†å‘ç”Ÿå˜åŒ–ï¼Œåˆ™ç»ˆæ­¢è¿­ä»£ï¼Œé¿å…æ— é™å¾ªç¯ã€‚

    å‚æ•°ï¼š
        segmented_head_y (list of list): å¤´éƒ¨ Y è½´æ•°æ®ï¼Œæ¯ä¸ªå­åˆ—è¡¨è¡¨ç¤ºä¸€ä¸ªæ—¶é—´åºåˆ—ç‰‡æ®µã€‚
        frame_window (int): ç”¨äºæ£€æµ‹çªå˜ç‚¹çš„å‰åçª—å£å¤§å°ï¼ˆé»˜è®¤ 400 å¸§ï¼‰ã€‚
        max_timestamps (int): å…è®¸çš„æœ€å¤§çªå˜ç‚¹æ•°é‡ï¼Œè¶…å‡ºåˆ™è·³è¿‡è¯¥æ®µæ•°æ®ï¼ˆé»˜è®¤ 8ï¼‰ã€‚
        smooth_window (int): å¹³æ»‘çª—å£å¤§å°ï¼ˆé»˜è®¤ 5ï¼‰ã€‚
        max_iterations (int): æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œé˜²æ­¢æ— é™å¾ªç¯ï¼ˆé»˜è®¤ 10ï¼‰ã€‚

    è¿”å›ï¼š
        tuple:
            - processed_data (list of list): å¤„ç†åçš„åˆ†å‰²æ•°æ®ã€‚
            - split_info (list): è®°å½• `segmented_head_y` çš„ç¬¬å‡ ä¸ªå…ƒç´ è¢«åˆ†å‰²å‡ æ¬¡ã€‚
    """

    # **åˆå§‹è¾“å…¥**
    processed_data = segmented_head_y
    split_info = list(range(len(segmented_head_y)))  # è®°å½•åˆå§‹ç´¢å¼•
    iteration = 0

    while iteration < max_iterations:
        iteration += 1
        new_processed_data = []
        new_split_info = []

        has_changes = False  # è¿½è¸ªæ˜¯å¦æœ‰æ–°çš„åˆ†å‰²æˆ–æ•°æ®æ¸…ç†

        for idx, segment in zip(split_info, processed_data):
            if len(segment) < 2 * frame_window:  # **æ•°æ®è¿‡çŸ­ï¼Œåˆ™è·³è¿‡**
                new_processed_data.append(segment)
                new_split_info.append(idx)
                continue

            segment = np.array(segment, dtype=float)

            # âœ… **1. è®¡ç®—è‡ªé€‚åº”é˜ˆå€¼**
            threshold = compute_adaptive_threshold(segment, "std", 1)

            # âœ… **2. æ£€æµ‹çªå˜ç‚¹**
            algo = rpt.Pelt(model="l2").fit(segment)
            change_points = algo.predict(pen=1)  # è·å–çªå˜ç‚¹ç´¢å¼•

            # âœ… **3. å¤„ç†çªå˜ç‚¹**
            invalid_indices = set()
            timestamps = []
            middle_timestamps = []  # è®°å½•ä¸­é—´çªå˜ç‚¹ï¼ˆæ’é™¤å‰ 400 å¸§å’Œå 400 å¸§ï¼‰

            for cp in change_points:
                if cp < frame_window:  # **å‰ 400 å¸§å†…**
                    before_mean = np.mean(segment[:cp])
                    after_mean = np.mean(segment[cp:cp + frame_window])
                    if abs(after_mean - before_mean) > threshold:
                        invalid_indices.update(range(0, cp + frame_window))

                elif cp > len(segment) - frame_window:  # **å 400 å¸§å†…**
                    before_mean = np.mean(segment[cp - frame_window:cp])
                    after_mean = np.mean(segment[cp:])
                    if abs(after_mean - before_mean) > threshold:
                        invalid_indices.update(range(cp - frame_window, len(segment)))

                else:  # **ä¸­é—´éƒ¨åˆ†**
                    before_mean = np.mean(segment[cp - frame_window:cp])
                    after_mean = np.mean(segment[cp:cp + frame_window])
                    if abs(after_mean - before_mean) > threshold:
                        timestamps.append(cp)
                        middle_timestamps.append(cp)  # è®°å½•ä¸­é—´éƒ¨åˆ†çªå˜ç‚¹

            # âœ… **4. å¤„ç†ä¸­é—´çš„çªå˜ç‚¹**
            if len(middle_timestamps) > max_timestamps:
                print(f"Skipping segment {idx} due to too many middle timestamps: {len(middle_timestamps)}")
                timestamps = []  # æ¸…ç©ºçªå˜ç‚¹ï¼Œé¿å…è¯¯åˆ†å‰²

            # âœ… **5. å¤„ç†ç›¸é‚»çªå˜ç‚¹**
            new_timestamps = []
            last_cp = None

            for cp in timestamps:
                if last_cp is not None and (cp - last_cp) < frame_window:
                    invalid_indices.update(range(last_cp, cp))  # æ ‡è®°è¯¥æ•°æ®æ— æ•ˆ
                else:
                    new_timestamps.append(cp)
                    last_cp = cp
            timestamps = new_timestamps  # **æ›´æ–° timestamps**

            # âœ… **6. å»é™¤æ— æ•ˆæ•°æ®**
            valid_indices = sorted(set(range(len(segment))) - invalid_indices)
            filtered_segment = segment[valid_indices]  # ä»…ä¿ç•™æœ‰æ•ˆæ•°æ®

            if len(valid_indices) < len(segment):  # **æ•°æ®è¢«ä¿®æ”¹**
                has_changes = True

            # âœ… **7. åˆ†å‰²æ•°æ®**
            split_segments = []
            last_cp = 0
            for cp in timestamps:
                if cp - last_cp > 10:  # **é¿å…åˆ†å‰²å¤ªçŸ­**
                    split_segments.append(filtered_segment[last_cp:cp])
                    new_split_info.append(idx)
                last_cp = cp

            if last_cp < len(filtered_segment):  # **æ·»åŠ æœ€åä¸€ä¸ªç‰‡æ®µ**
                split_segments.append(filtered_segment[last_cp:])
                new_split_info.append(idx)

            if len(split_segments) > 1:  # **å‘ç”Ÿäº†åˆ†å‰²**
                has_changes = True

            # âœ… **8. å¹³æ»‘æ–­ç‚¹**
            final_segments = []
            for sub_segment in split_segments:
                if len(sub_segment) > smooth_window:
                    sub_segment = savgol_filter(sub_segment, smooth_window, polyorder=2)
                final_segments.append(sub_segment)

            new_processed_data.extend(final_segments)

        # **æ£€æŸ¥æ˜¯å¦è¿˜æœ‰å˜åŒ–**
        if not has_changes:
            print(f"Converged after {iteration} iterations.")
            break

        # **æ›´æ–° processed_data å’Œ split_info**
        processed_data = new_processed_data
        split_info = new_split_info

    return processed_data, split_info

def detect_periodicity_acf_with_peaks(data, threshold=0.2, max_lag=300, min_ratio=0.4, min_alternations=6):
    """
    ä½¿ç”¨è‡ªç›¸å…³å‡½æ•° (ACF) æ£€æµ‹æ—¶é—´åºåˆ—æ˜¯å¦å…·æœ‰å‘¨æœŸæ€§ï¼Œå¹¶è®¡ç®—æœ€é«˜å³°å€¼å’Œæœ€ä½å³°å€¼ã€‚

    ä¸»è¦é€»è¾‘ï¼š
    1. **è®¡ç®— ACFï¼ˆè‡ªç›¸å…³å‡½æ•°ï¼‰**ï¼š
       - è®¡ç®— `max_lag` å†…çš„è‡ªç›¸å…³å€¼ï¼Œç”¨äºåˆ†ææ•°æ®çš„å‘¨æœŸæ€§ã€‚
    2. **ç»Ÿè®¡æ»åæ­¥é•¿ä¸­æ˜¾è‘—ç›¸å…³çš„æ¯”ä¾‹**ï¼š
       - è®¡ç®— `|ACF| > threshold` çš„æ»åå€¼å æ¯” `ratio`ã€‚
    3. **è®¡ç®— ACF çš„ç¬¦å·å˜åŒ–**ï¼š
       - è®¡ç®— `sign_changes`ï¼ˆACF çš„æ­£è´Ÿå·ï¼‰ã€‚
       - è®¡ç®— `alternation_count`ï¼ˆACF çš„æ­£è´Ÿäº¤æ›¿æ¬¡æ•°ï¼‰ã€‚
    4. **åˆ¤æ–­å‘¨æœŸæ€§**ï¼š
       - åªæœ‰å½“ `ratio > min_ratio` ä¸” `alternation_count >= min_alternations` æ—¶ï¼Œè®¤ä¸ºæ•°æ®å…·æœ‰å‘¨æœŸæ€§ã€‚
    5. **è®¡ç®—å‡å€¼å’ŒæŒ¯å¹…**ï¼š
       - è®¡ç®—æ•°æ®çš„ `mean`ã€‚
       - è®¡ç®— `amp`ï¼ˆæ•°æ®çš„ FFT æŒ¯å¹…ï¼Œéœ€è°ƒç”¨ `compute_amplitude_fft`ï¼‰ã€‚

    å‚æ•°ï¼š
        data (array-like): æ—¶é—´åºåˆ—æ•°æ®ã€‚
        threshold (float): è‡ªç›¸å…³ç³»æ•°é˜ˆå€¼ï¼Œç»å¯¹å€¼å¤§äºæ­¤å€¼æ‰ç®—æ˜¾è‘—ç›¸å…³ï¼ˆé»˜è®¤ 0.2ï¼‰ã€‚
        max_lag (int): è®¡ç®— ACF æ—¶çš„æœ€å¤§æ»åæ­¥é•¿ï¼ˆé»˜è®¤ 300ï¼‰ã€‚
        min_ratio (float): å¤šå°‘æ¯”ä¾‹çš„æ»åå€¼éœ€è¦è¶…è¿‡ `threshold` æ‰ç®—å‘¨æœŸæ€§ï¼ˆé»˜è®¤ 0.4ï¼‰ã€‚
        min_alternations (int): è‡³å°‘å¤šå°‘æ¬¡æ­£è´Ÿäº¤æ›¿æ‰ç®—å‘¨æœŸæ€§ï¼ˆé»˜è®¤ 6ï¼‰ã€‚

    è¿”å›ï¼š
        tuple:
            - periodic (bool): æ˜¯å¦å­˜åœ¨å‘¨æœŸæ€§ã€‚
            - mean (float): æ•°æ®å‡å€¼ã€‚
            - amp (float): æ•°æ®çš„ FFT æŒ¯å¹…ã€‚
    """

    # **è®¡ç®— ACF**
    acf_values = sm.tsa.acf(data, nlags=max_lag)

    # **ç»Ÿè®¡ |ACF| è¶…è¿‡ threshold çš„æ»åç‚¹æ•°é‡**
    above_threshold = np.sum(np.abs(acf_values[1:]) > threshold)  # ç»Ÿè®¡æ˜¾è‘—ç›¸å…³çš„ç‚¹
    ratio = above_threshold / max_lag  # è®¡ç®—å æ¯”

    # **è®¡ç®— ACF çš„æ­£è´Ÿå˜åŒ–**
    sign_changes = np.sign(acf_values[1:])  # è·å– ACF çš„æ­£è´Ÿå· (+1 æˆ– -1)
    alternation_count = np.sum(np.diff(sign_changes) != 0)  # è®¡ç®—æ­£è´Ÿäº¤æ›¿æ¬¡æ•°

    # **åˆ¤æ–­å‘¨æœŸæ€§**
    periodic = (ratio > min_ratio) and (alternation_count >= min_alternations)

    # **è®¡ç®—å‡å€¼**
    mean = np.mean(data)

    # **è®¡ç®—æ•°æ®çš„ FFT æŒ¯å¹…**
    amp = compute_amplitude_fft(data)  # éœ€è¦ `compute_amplitude_fft()` æ–¹æ³•æ”¯æŒ

    return periodic, mean, amp

def split_orientation_segments(orientation_segments, segmented_head_y, split_info):
    """
    æ ¹æ® segmented_head_y å’Œ split_info å¯¹ orientation_segments è¿›è¡Œç›¸åº”çš„åˆ†å‰²ï¼Œ
    å¹¶æŒ‰æ¯”ä¾‹åˆ†é…å¸§æ•°ï¼Œä»¥ä¿æŒæ•°æ®å®Œæ•´æ€§ã€‚

    ä¸»è¦é€»è¾‘ï¼š
    1. **è®¡ç®—åŸå§‹ç‰‡æ®µçš„ frame åˆ†é…æƒ…å†µ**ï¼š
       - è®°å½•æ¯ä¸ª `orientation_segments` ç‰‡æ®µå¯¹åº”çš„ `segmented_head_y` ç‰‡æ®µæ€»é•¿åº¦ (`segment_lengths`)ã€‚
    2. **éå† segmented_head_y å¹¶è¿›è¡Œåˆ†å‰²**ï¼š
       - æŒ‰æ¯”ä¾‹è®¡ç®—æ–°çš„ `duration_frames`ï¼Œç¡®ä¿å¸§æ•°åˆ†é…åˆç†ã€‚
       - ç¡®ä¿ `start_frame` å’Œ `end_frame` è¿ç»­ï¼Œé¿å…æ•°æ®ä¸è¿è´¯ã€‚
    3. **ç”Ÿæˆæ–°ç‰‡æ®µ**ï¼š
       - è®¡ç®—æ–°çš„ `duration_sec`ï¼Œä¿æŒ `FPS` ä¸€è‡´ã€‚
       - åˆ›å»ºæ–°çš„ `orientation_segments`ï¼Œå­˜å‚¨åœ¨ `new_segments` åˆ—è¡¨ä¸­ã€‚

    å‚æ•°ï¼š
        orientation_segments (list[dict]): åŸå§‹å§¿æ€ç‰‡æ®µï¼Œæ¯ä¸ªå­—å…¸åŒ…å«:
            - "orient": å§¿æ€æ–¹å‘
            - "start_frame": ç‰‡æ®µèµ·å§‹å¸§ç´¢å¼•
            - "end_frame": ç‰‡æ®µç»“æŸå¸§ç´¢å¼•
            - "duration_sec": ç‰‡æ®µæŒç»­æ—¶é—´ï¼ˆç§’ï¼‰
            - "duration_frames": ç‰‡æ®µæŒç»­å¸§æ•°
        segmented_head_y (list[list[float]]): åˆ†å‰²åçš„æ—¶é—´åºåˆ—æ•°æ®ï¼Œæ¯ä¸ªå­åˆ—è¡¨å¯¹åº”ä¸€ä¸ªåˆ†å‰²éƒ¨åˆ†ã€‚
        split_info (list[int]): æŒ‡ç¤º `segmented_head_y` æ¯ä¸ªå…ƒç´ å±äºå“ªä¸ª `orientation_segments` ç‰‡æ®µã€‚

    è¿”å›ï¼š
        list[dict]: é‡æ–°åˆ†å‰²åçš„ `orientation_segments` ç‰‡æ®µåˆ—è¡¨ã€‚
    """

    new_segments = []

    # è®°å½•æ¯ä¸ªåŸå§‹ç‰‡æ®µçš„ frame åˆ†é…æƒ…å†µ
    segment_allocations = {}  

    # è®¡ç®—æ¯ä¸ª segment_index å…³è”çš„ segmented_head_y ç‰‡æ®µæ€»é•¿åº¦
    segment_lengths = {}
    for i, segment_data in enumerate(segmented_head_y):
        segment_index = split_info[i]
        segment_lengths[segment_index] = segment_lengths.get(segment_index, 0) + len(segment_data)

    # éå† segmented_head_y å¹¶è¿›è¡Œåˆ†å‰²
    for i, segment_data in enumerate(segmented_head_y):
        segment_index = split_info[i]  # è¯¥æ•°æ®ç‰‡æ®µå±äºå“ªä¸ªåŸ `orientation_segments` ç‰‡æ®µ
        orig_segment = orientation_segments[segment_index]  # è·å–åŸå§‹ `orientation_segments` ç‰‡æ®µ

        # è·å–åŸå§‹ç‰‡æ®µçš„ä¿¡æ¯
        orig_start_frame = orig_segment["start_frame"]
        orig_duration_frames = orig_segment["duration_frames"]

        # æŒ‰æ¯”ä¾‹è®¡ç®—æ–°çš„ `duration_frames`
        total_segment_length = segment_lengths[segment_index]  # è¯¥ç‰‡æ®µæ‰€æœ‰ `segmented_head_y` æ•°æ®æ€»é•¿åº¦
        ratio = len(segment_data) / total_segment_length
        new_duration_frames = round(ratio * orig_duration_frames)

        # ç¡®ä¿ç‰‡æ®µæ˜¯è¿ç»­çš„
        if segment_index not in segment_allocations:
            segment_allocations[segment_index] = orig_start_frame
        start_frame = segment_allocations[segment_index]
        end_frame = start_frame + new_duration_frames - 1

        # è®¡ç®—å¸§ç‡ (FPS) ä»¥è½¬æ¢ `duration_frames -> duration_sec`
        fps = orig_segment["duration_sec"] / orig_duration_frames
        duration_sec = new_duration_frames * fps

        # ç”Ÿæˆæ–°ç‰‡æ®µ
        new_segment = {
            "orient": orig_segment["orient"],
            "start_frame": start_frame,
            "end_frame": end_frame,
            "duration_sec": duration_sec,
            "duration_frames": new_duration_frames,
        }
        new_segments.append(new_segment)

        # æ›´æ–°èµ·å§‹ä½ç½®ï¼Œç¡®ä¿ä¸‹ä¸€ç‰‡æ®µçš„ `start_frame` è¿ç»­
        segment_allocations[segment_index] = end_frame + 1

    return new_segments

def compute_amplitude_fft(time_series):
    """
    è®¡ç®—ä¸»é¢‘åŠå…¶å¯¹åº”çš„æŒ¯å¹…ï¼ˆåŸºäº FFTï¼‰ã€‚

    ä¸»è¦é€»è¾‘ï¼š
    1. **è®¡ç®— FFTï¼ˆå¿«é€Ÿå‚…é‡Œå¶å˜æ¢ï¼‰**ï¼š
       - è·å– `time_series` çš„é¢‘è°±ä¿¡æ¯ã€‚
    2. **è®¡ç®—æŒ¯å¹…è°±**ï¼š
       - å½’ä¸€åŒ–è®¡ç®—æŒ¯å¹…ï¼Œä½¿å¾—æŒ¯å¹…å¤§å°ç‹¬ç«‹äºæ•°æ®é•¿åº¦ã€‚
    3. **è·å–ä¸»é¢‘çš„æŒ¯å¹…**ï¼š
       - ä»…ä½¿ç”¨æ­£é¢‘ç‡éƒ¨åˆ†ï¼ˆFFT ç»“æœçš„å‰åŠéƒ¨åˆ†ï¼‰ã€‚
       - å¿½ç•¥é›¶é¢‘ï¼ˆç›´æµåˆ†é‡ï¼‰ï¼Œæ‰¾åˆ°æŒ¯å¹…æœ€å¤§çš„é¢‘ç‡åˆ†é‡ã€‚

    å‚æ•°ï¼š
        time_series (array-like): è¾“å…¥çš„æ—¶é—´åºåˆ—æ•°æ®ã€‚

    è¿”å›ï¼š
        float: ä¸»é¢‘å¯¹åº”çš„æŒ¯å¹…ã€‚
    """

    N = len(time_series)  # **æ•°æ®é•¿åº¦**
    fft_values = np.fft.fft(time_series)  # **è®¡ç®— FFT**
    
    # **è®¡ç®—æŒ¯å¹…è°±ï¼ˆå½’ä¸€åŒ–å¤„ç†ï¼‰**
    amplitude_spectrum = (2 / N) * np.abs(fft_values)  # **æŒ¯å¹…å½’ä¸€åŒ–**

    # **å–æ­£é¢‘ç‡éƒ¨åˆ†ï¼ˆå»æ‰è´Ÿé¢‘ç‡ï¼‰**
    positive_amplitude = amplitude_spectrum[:N // 2]

    # **æ‰¾åˆ°ä¸»é¢‘ç´¢å¼•ï¼ˆå¿½ç•¥é›¶é¢‘ï¼‰**
    main_freq_index = np.argmax(positive_amplitude[1:]) + 1  # **è·³è¿‡ç›´æµåˆ†é‡ï¼ˆDCï¼‰**
    main_amplitude = positive_amplitude[main_freq_index]

    return main_amplitude

def update_orientation_segments(orientation_segments, periodics, means, amps):
    """
    æ ¹æ® `periodics`ã€`means` å’Œ `amps` æ›´æ–° `orientation_segments`ï¼Œæ·»åŠ  `head_y` å€¼ï¼š
    
    ä¸»è¦é€»è¾‘ï¼š
    1. **åˆ¤æ–­æ˜¯å¦å­˜åœ¨å‘¨æœŸæ€§**ï¼š
       - è‹¥ `periodics[i] == True`ï¼Œåˆ™ `head_y = [means[i] - amps[i], means[i] + amps[i]]`ã€‚
       - è‹¥ `periodics[i] == False`ï¼Œåˆ™ `head_y = means[i]`ï¼ˆæ— æ˜æ˜¾å‘¨æœŸæ€§ï¼Œç›´æ¥èµ‹å€¼ï¼‰ã€‚
    2. **æ›´æ–° `orientation_segments`**ï¼š
       - éå† `orientation_segments`ï¼Œä¸ºæ¯ä¸ªç‰‡æ®µè®¡ç®— `head_y` å¹¶å­˜å…¥å­—å…¸ã€‚

    å‚æ•°ï¼š
        orientation_segments (list[dict]): å¾…æ›´æ–°çš„å§¿æ€ç‰‡æ®µåˆ—è¡¨ï¼Œæ¯ä¸ªå­—å…¸åŒ…å«ï¼š
            - "orient": å§¿æ€æ–¹å‘
            - "start_frame": ç‰‡æ®µèµ·å§‹å¸§ç´¢å¼•
            - "end_frame": ç‰‡æ®µç»“æŸå¸§ç´¢å¼•
            - "duration_sec": ç‰‡æ®µæŒç»­æ—¶é—´ï¼ˆç§’ï¼‰
            - "duration_frames": ç‰‡æ®µæŒç»­å¸§æ•°
        periodics (list[bool]): æ˜¯å¦å­˜åœ¨å‘¨æœŸæ€§ (True / False)ã€‚
        means (list[float]): æ¯ä¸ªç‰‡æ®µçš„å‡å€¼ã€‚
        amps (list[float]): æ¯ä¸ªç‰‡æ®µçš„æŒ¯å¹…ï¼ˆå‘¨æœŸæ€§æŒ¯å¹…ï¼‰ã€‚

    è¿”å›ï¼š
        list[dict]: åŒ…å« `head_y` ä¿¡æ¯çš„ `orientation_segments`ã€‚
    """

    for i in range(len(orientation_segments)):
        if periodics[i]:
            orientation_segments[i]["head_y"] = [means[i] - amps[i], means[i] + amps[i]]  # **è®¾å®šåŒºé—´**
        else:
            orientation_segments[i]["head_y"] = means[i]  # **æ— å‘¨æœŸæ€§ï¼Œç›´æ¥èµ‹å€¼**

    return orientation_segments

def plot_combined_single_axis(head_y, orientation_durations):
    """
    åœ¨åŒä¸€å¼ å›¾ä¸Šç»˜åˆ¶å¤´éƒ¨é«˜åº¦å˜åŒ–æ›²çº¿ï¼Œå¹¶ç”¨å¡«å……åŒºåŸŸè¡¨ç¤ºä¸åŒçš„é¢éƒ¨æœå‘åŒºåŸŸã€‚
    å¯¹äº `motion_state` ä¸º "Static" çš„åŒºåŸŸï¼Œä½¿ç”¨æ–œçº¿å¡«å……è¿›è¡Œæ ‡è®°ã€‚

    ä¸»è¦é€»è¾‘ï¼š
    1. **æ£€æŸ¥è¾“å…¥æ•°æ®æ˜¯å¦ä¸ºç©º**ï¼š
       - å¦‚æœ `head_y` æˆ– `orientation_durations` ä¸ºç©ºï¼Œåˆ™è¿”å›é”™è¯¯æç¤ºã€‚
    2. **ç¡®å®šç»˜åˆ¶åŒºé—´**ï¼š
       - è®¡ç®— `start_frame` å’Œ `end_frame`ï¼Œç¡®ä¿ç´¢å¼•èŒƒå›´åœ¨ `head_y` æœ‰æ•ˆèŒƒå›´å†…ã€‚
    3. **å¤„ç† `head_y` æ•°æ®**ï¼š
       - ç”¨ `NaN` ä»£æ›¿ `None` å€¼ï¼Œå¹¶ä½¿ç”¨ `pandas.interpolate()` è¿›è¡Œçº¿æ€§æ’å€¼ï¼Œä»¥å¹³æ»‘æ•°æ®ã€‚
    4. **ç»˜åˆ¶å¤´éƒ¨é«˜åº¦å˜åŒ–æ›²çº¿**ï¼š
       - ä½¿ç”¨ `plt.plot()` ç»˜åˆ¶ `head_y` éšæ—¶é—´çš„å˜åŒ–ã€‚
    5. **å¡«å……é¢éƒ¨æœå‘åŒºåŸŸ**ï¼š
       - å®šä¹‰ `Height_map`ï¼Œç”¨äºå°†ä¸åŒçš„ `orientation` æ˜ å°„åˆ°ç‰¹å®šçš„å¯è§†åŒ–é«˜åº¦ã€‚
       - å®šä¹‰ `color_map`ï¼Œç”¨äºæŒ‡å®šä¸åŒ `orientation` å¯¹åº”çš„å¡«å……é¢œè‰²ã€‚
       - éå† `orientation_durations`ï¼Œä½¿ç”¨ `plt.fill_between()` å¡«å……åŒºåŸŸã€‚
    6. **æ ‡è®° `motion_state` ä¸º "Static" çš„ç‰‡æ®µ**ï¼š
       - å¦‚æœç‰‡æ®µçš„ `motion_state` ä¸º "Static"ï¼Œåœ¨å¡«å……åŒºåŸŸä¸Šå åŠ é»‘è‰²æ–œçº¿ `hatch='//'` è¿›è¡Œæ ‡è®°ã€‚

    å‚æ•°ï¼š
        head_y (list[float]): å¤´éƒ¨é«˜åº¦æ•°æ®ï¼Œæ¯ä¸ªç´¢å¼•å¯¹åº”ä¸€ä¸ªå¸§ã€‚
        orientation_durations (list[dict]): åŒ…å«é¢éƒ¨æœå‘ä¿¡æ¯çš„ç‰‡æ®µï¼Œæ¯ä¸ªç‰‡æ®µåŒ…å«ï¼š
            - "start_frame": ç‰‡æ®µèµ·å§‹å¸§ç´¢å¼•ã€‚
            - "end_frame": ç‰‡æ®µç»“æŸå¸§ç´¢å¼•ã€‚
            - "orient": ç‰‡æ®µçš„é¢éƒ¨æœå‘ï¼ˆå¦‚ "neutral", "right", "up", "down"ï¼‰ã€‚
            - "motion_state" (å¯é€‰): æ˜¯å¦ä¸º "Static"ï¼Œå¦‚æœæ˜¯ï¼Œåˆ™ç”¨æ–œçº¿å¡«å……ã€‚

    è¿”å›ï¼š
        None: ç›´æ¥åœ¨ `matplotlib` ç”»å¸ƒä¸Šç»˜åˆ¶å›¾åƒï¼Œä¸è¿”å›å€¼ã€‚

    """

    # **æ£€æŸ¥è¾“å…¥æ•°æ®æ˜¯å¦ä¸ºç©º**
    if not head_y:
        print("é”™è¯¯: head_y ä¸ºç©ºï¼Œæ— æ³•ç»˜åˆ¶å›¾è¡¨ã€‚")
        return
    
    if not orientation_durations:
        print("é”™è¯¯: orientation_durations ä¸ºç©ºï¼Œæ— æ³•ç¡®å®šç»˜åˆ¶åŒºé—´ã€‚")
        return

    # **ç¡®å®šç»˜åˆ¶åŒºé—´**
    start_frame = min(seg["start_frame"] for seg in orientation_durations)
    end_frame = max(seg["end_frame"] for seg in orientation_durations)

    start_frame = max(0, start_frame)
    end_frame = min(len(head_y) - 1, end_frame)

    # **å¤„ç† head_y æ•°æ®ï¼šæ’å€¼å¡«å……ç¼ºå¤±å€¼**
    filtered_head_y = [head_y[i] if head_y[i] is not None else np.nan for i in range(start_frame, end_frame + 1)]
    filtered_head_y = pd.Series(filtered_head_y).interpolate(method='linear').tolist()

    x_values = np.arange(start_frame, end_frame + 1)

    # **åˆ›å»º Matplotlib ç”»å¸ƒ**
    plt.figure(figsize=(10, 5))

    # **ç»˜åˆ¶ head_y é«˜åº¦å˜åŒ–æ›²çº¿**
    plt.plot(x_values, filtered_head_y, marker='o', markersize=3, linestyle='-', color='b', label='Height Variation')

    # **å®šä¹‰å§¿åŠ¿å¯¹åº”çš„å¯è§†åŒ–é«˜åº¦**
    Height_map = {
        'neutral': 2,
        'right': 4,
        'up': 3,
        'down': 1,
        'down-neutral': 1.5,
        'neutral-down': 1.5,
        'up-neutral': 2.5,
        'neutral-up': 2.5
    }

    # **å®šä¹‰é¢œè‰²æ˜ å°„**
    color_map = {
        'neutral': '#8dd3c7',
        # 'right': '#ffffb3',
        'up': '#fb8072',
        'down': '#ffffb3',
        'down-neutral': '#fdb462',
        'neutral-down': '#fdb462',
        'up-neutral': '#b3de69',
        'neutral-up': '#b3de69',
        'down-up': '#fccde5',
        'up-down': '#fccde5'
    }

    # **éå† orientation_durationsï¼Œå¡«å……å§¿åŠ¿åŒºåŸŸ**
    for entry in orientation_durations:
        start_time = entry["start_frame"]
        end_time = entry["end_frame"]
        Height = Height_map.get(entry["orient"], 2)  # é»˜è®¤å€¼ä¸º 2ï¼Œé˜²æ­¢ key é”™è¯¯

        # **å¡«å……èƒŒæ™¯è‰²**
        plt.fill_between([start_time, end_time], 0, Height, 
                         color=color_map.get(entry["orient"], 'gray'), alpha=0.5, 
                         label=entry["orient"] if entry["orient"] not in plt.gca().get_legend_handles_labels()[1] else "")

        # **æ ‡è®° motion_state ä¸º "Static" çš„åŒºåŸŸ**
        if entry.get("motion_state") == "Static":
            plt.fill_between([start_time, end_time], 0, Height, 
                             facecolor='none', edgecolor='black', hatch='//', alpha=0.5)

    # **æ·»åŠ å›¾ä¾‹ã€æ ‡é¢˜ã€æ ‡ç­¾ã€ç½‘æ ¼**
    plt.xlabel("Frame Index")
    plt.ylabel("Height Level / Face Orientation")
    plt.title("Head Height & Face Orientation Variation Over Time")
    plt.legend()
    plt.grid(True, linestyle='--', alpha=0.6)

    # **æ˜¾ç¤ºå›¾åƒ**
    plt.show()

def plot_orientation_segments(orientation_segments):
    """
    ç»˜åˆ¶ `head_y` å˜åŒ–ï¼ˆåŸºäº `orientation_segments["head_y"]`ï¼‰å¹¶å¡«å……ç‰‡æ®µä¸‹æ–¹çš„åŒºåŸŸï¼Œ
    å¤„ç†ç‰‡æ®µé—´æ–­ç‚¹ï¼Œå¹¶åœ¨ `Static` ç‰‡æ®µä¸Šè¦†ç›–äº¤å‰çº¿ï¼ŒåŒæ—¶æ ‡æ³¨ `orient` æ–¹å‘ã€‚

    å‚æ•°ï¼š
        orientation_segments (list[dict]): å§¿æ€ç‰‡æ®µåˆ—è¡¨ï¼Œæ¯ä¸ªå­—å…¸åŒ…å«ï¼š
            - "start_frame": ç‰‡æ®µèµ·å§‹å¸§ç´¢å¼•ã€‚
            - "end_frame": ç‰‡æ®µç»“æŸå¸§ç´¢å¼•ã€‚
            - "head_y": å¤´éƒ¨é«˜åº¦ (å•å€¼æˆ– `[min, max]` åŒºé—´)ã€‚
            - "orient": å§¿åŠ¿æ–¹å‘ï¼ˆå¦‚ "neutral", "right", "up", "down"ï¼‰ã€‚

    è¿”å›ï¼š
        None: ç›´æ¥åœ¨ `matplotlib` ç”»å¸ƒä¸Šç»˜åˆ¶å›¾åƒï¼Œä¸è¿”å›å€¼ã€‚
    """

    if not orientation_segments:
        print("é”™è¯¯: orientation_segments ä¸ºç©ºï¼Œæ— æ³•ç»˜åˆ¶å›¾è¡¨ã€‚")
        return
    
    try:
        # è¯»å–å›¾ç‰‡
        # è¯»å–å›¾ç‰‡
        img_path = "full_body.png"
        img = Image.open(img_path)
        img_width, img_height = img.size
        aspect_ratio = img_width / img_height
        print(f"âœ… å›¾ç‰‡åŠ è½½æˆåŠŸ: {img_path} (å®½: {img_width}, é«˜: {img_height})")
    except Exception as e:
        print(f"âŒ å›¾ç‰‡åŠ è½½å¤±è´¥: {e}")
        return
    
    
    
    # åˆ›å»ºä¸»å›¾
    fig, ax = plt.subplots(figsize=(12, 6))

    # **å®šä¹‰é¢œè‰²æ˜ å°„**
    color_map = {
        'neutral': '#8dd3c7',
        # 'right': '#ffffb3',
        'up': '#fb8072',
        'down': '#bebada',
        'down-neutral': '#fdb462',
        'neutral-down': '#fdb462',
        'up-neutral': '#b3de69',
        'neutral-up': '#b3de69',
        'down-up': '#fccde5',
        'up-down': '#fccde5'
    }

    # **éå† orientation_segmentsï¼Œç»˜åˆ¶ head_y è½¨è¿¹**
    for entry in orientation_segments:
        start_time = entry["start_frame"]
        end_time = entry["end_frame"]
        head_y = entry["head_y"]
        orient = entry["orient"]

        # **è·å–é¢œè‰²**
        color = color_map.get(orient, 'gray')

        # **ç”Ÿæˆ x è½´æ•°æ®**
        x_values = np.arange(start_time, end_time + 1)

        # **ç”Ÿæˆ y è½´æ•°æ®**
        if isinstance(head_y, (int, float)):  # **å•å€¼ï¼Œç»˜åˆ¶æ°´å¹³ç›´çº¿**
            y_values = np.full_like(x_values, head_y, dtype=float)

        elif isinstance(head_y, (list, tuple)) and len(head_y) == 2:  # **åŒºé—´å€¼ï¼Œç»˜åˆ¶æŒ¯è¡æ›²çº¿**
            min_val, max_val = head_y
            num_points = len(x_values)
            num_oscillations = 3  # æŒ‡å®šå¾€è¿”çš„æ¬¡æ•°

            # ä¸­é—´å€¼ (èµ·ç‚¹ä¸ç»ˆç‚¹)
            mid_val = (min_val + max_val) / 2

            # è®¡ç®—æ¯æ¬¡å¾€è¿”å ç”¨çš„ç‚¹æ•°ï¼ˆä¸¤ä¸ªæ¥å›ä¸ºä¸€ç»„ï¼‰
            points_per_oscillation = num_points // (num_oscillations * 4)
            
            indices = []
            for _ in range(num_oscillations):
                # ç”Ÿæˆä¸€ä¸ªå®Œæ•´çš„å¾€è¿”ï¼šä¸­é—´å€¼ -> max_val -> ä¸­é—´å€¼ -> min_val -> ä¸­é—´å€¼
                indices.extend(np.linspace(mid_val, max_val, points_per_oscillation))   # ä¸­é—´å€¼ -> æœ€å¤§å€¼
                indices.extend(np.linspace(max_val, mid_val, points_per_oscillation))   # æœ€å¤§å€¼ -> ä¸­é—´å€¼
                indices.extend(np.linspace(mid_val, min_val, points_per_oscillation))   # ä¸­é—´å€¼ -> æœ€å°å€¼
                indices.extend(np.linspace(min_val, mid_val, points_per_oscillation))   # æœ€å°å€¼ -> ä¸­é—´å€¼

            # å¦‚æœç‚¹æ•°ä¸å¤Ÿï¼Œè¡¥ä¸Šä¸­é—´ç‚¹
            if len(indices) < num_points:
                indices = np.concatenate([indices, [mid_val] * (num_points - len(indices))])
            
            y_values = np.array(indices[:num_points])  # ç¡®ä¿ y_values çš„é•¿åº¦ä¸ x_values ä¸€è‡´
                
        else:
            continue  # **æ•°æ®æ ¼å¼é”™è¯¯ï¼Œè·³è¿‡**

        # **å¡«å……æ›²çº¿ä¸‹æ–¹çš„åŒºåŸŸ**
        plt.fill_between(x_values, y_values, 0, color=color, alpha=0.5, label=orient if orient not in plt.gca().get_legend_handles_labels()[1] else "")

        # **åœ¨ orientation ç‰‡æ®µé¡¶éƒ¨æ ‡æ³¨ orient**
        mid_x = (start_time + end_time) / 2
        mid_y = max(y_values) + 0.01  # **è®©æ–‡æœ¬ç¨å¾®é«˜äºæ›²çº¿**
        if '-' in orient:  # å¦‚æœæ˜¯è¿æ¥è¯
            word1, word2 = orient.split('-')
            # åˆ¤æ–­è¾ƒé•¿çš„å•è¯å’Œè¾ƒçŸ­çš„å•è¯
            if len(word1) >= len(word2):
                plt.text(mid_x, mid_y + 0.03, word1, fontsize=10 , ha='center', va='bottom', color='black', fontfamily='Arial')
                plt.text(mid_x, mid_y, f'&{word2}', fontsize=10, ha='center', va='bottom', color='black', fontfamily='Arial')
            else:
                plt.text(mid_x, mid_y + 0.03, word2, fontsize=10, ha='center', va='bottom', color='black', fontfamily='Arial')
                plt.text(mid_x, mid_y, f'&{word1}', fontsize=10, ha='center', va='bottom', color='black', fontfamily='Arial')
        else:  # å¦‚æœæ˜¯å•è¯
            plt.text(mid_x, mid_y, orient, fontsize=10, ha='center', va='bottom', color='black', fontfamily='Arial')


    # **æ·»åŠ å›¾ä¾‹ã€æ ‡ç­¾ã€ç½‘æ ¼**
    plt.ylim(0, 1.1)
    plt.xlabel("Frame Index")
    plt.ylabel("Eye Height (Normalized)")
    plt.title("Nose Height and Facial Orientation Over Time")
    plt.legend(prop={'family': 'Arial'})
    plt.grid(True, linestyle='--', alpha=0.6)

    # åœ¨å·¦ä¾§æ·»åŠ å›¾ç‰‡
    target_height =  0.72
    target_width = target_height * aspect_ratio
    ax_img = fig.add_axes([0.03, 0.1, target_width, target_height], anchor='W')  # ç¡®ä¿å›¾ç‰‡çš„é«˜åº¦ä¸ 0-1 å¯¹é½
    ax_img.imshow(img)
    ax_img.axis('off')
    ax_img.set_zorder(0)

    # **æ˜¾ç¤ºå›¾åƒ**
    plt.show()

def plot_orientation_segments(orientation_segments, save_path):
    """
    ç»˜åˆ¶ `head_y` å˜åŒ–ï¼ˆåŸºäº `orientation_segments["head_y"]`ï¼‰å¹¶å¡«å……ç‰‡æ®µä¸‹æ–¹çš„åŒºåŸŸï¼Œ
    å¤„ç†ç‰‡æ®µé—´æ–­ç‚¹ï¼Œå¹¶åœ¨ `Static` ç‰‡æ®µä¸Šè¦†ç›–äº¤å‰çº¿ï¼ŒåŒæ—¶æ ‡æ³¨ `orient` æ–¹å‘ã€‚

    å‚æ•°ï¼š
        orientation_segments (list[dict]): å§¿æ€ç‰‡æ®µåˆ—è¡¨ï¼Œæ¯ä¸ªå­—å…¸åŒ…å«ï¼š
            - "start_frame": ç‰‡æ®µèµ·å§‹å¸§ç´¢å¼•ã€‚
            - "end_frame": ç‰‡æ®µç»“æŸå¸§ç´¢å¼•ã€‚
            - "head_y": å¤´éƒ¨é«˜åº¦ (å•å€¼æˆ– `[min, max]` åŒºé—´)ã€‚
            - "orient": å§¿åŠ¿æ–¹å‘ï¼ˆå¦‚ "neutral", "right", "up", "down"ï¼‰ã€‚

    è¿”å›ï¼š
        None: ç›´æ¥åœ¨ `matplotlib` ç”»å¸ƒä¸Šç»˜åˆ¶å›¾åƒï¼Œä¸è¿”å›å€¼ã€‚
    """

    if not orientation_segments:
        print("é”™è¯¯: orientation_segments ä¸ºç©ºï¼Œæ— æ³•ç»˜åˆ¶å›¾è¡¨ã€‚")
        return
    
    try:
        # è¯»å–å›¾ç‰‡
        # è¯»å–å›¾ç‰‡
        left_img_path = os.path.join(IMAGE_FOLDER, 'full_body.png')
        left_img = Image.open(left_img_path)
        img_width, img_height = left_img.size
        aspect_ratio = img_width / img_height
        # right_img_path = os.path.join(IMAGE_FOLDER, 'indicator.png')
        # right_img = Image.open(right_img_path)
    except Exception as e:
        print(f"âŒ å›¾ç‰‡åŠ è½½å¤±è´¥: {e}")
        return
    
    
    target_width_px, target_height_px = 1280, 600
    dpi = 100  # æ¯è‹±å¯¸çš„åƒç´ ç‚¹æ•°
    # è½¬æ¢ä¸ºè‹±å¯¸
    fig_width, fig_height = target_width_px / dpi, target_height_px / dpi
    # åˆ›å»ºå›¾å½¢
    fig, ax = plt.subplots(figsize=(fig_width, fig_height))
    original_position = ax.get_position()  # è·å– ax çš„ä½ç½®ä¿¡æ¯
    new_position = [original_position.x0 + 0.05, original_position.y0,
                original_position.width, original_position.height]
    print(new_position)
    ax.set_position(new_position)

    # **å®šä¹‰é¢œè‰²æ˜ å°„**
    color_map = {
        'neutral': '#59C9A5',
        # 'right': '#ffffb3',
        'up': '#FC9F5B',
        'down': '#D7B9D5',
        'neutral-down': '#1E96FC',
        'neutral-up': '#b3de69',
        'down-up': '#DE425B',
    }

    # previous_orient = None
    # accumulated_start_time = None
    # accumulated_end_time = None
    # accumulated_y_values = []

    total_frames = 0
    standing_frames = 0
    down_frames = 0
    transitions_count = 0  # Count of transitions
    total_low_frames = 0  # Total frames where head_y <= 0.6
    store_frames = 0

    # Track the previous state (None means uninitialized)
    previous_state = None  # Can be 'high' (>0.8), 'low' (<0.6), or None
    store_state = None

    # **éå† orientation_segmentsï¼Œç»˜åˆ¶ head_y è½¨è¿¹**
    for entry in orientation_segments:
        start_time = entry["start_frame"]
        end_time = entry["end_frame"]
        head_y = entry["head_y"]
        orient = entry["orient"]
        duration_frames = entry['duration_frames']

        total_frames += duration_frames
        current_state = None
        if isinstance(head_y, (int, float)):
            if head_y > 0.6:
                current_state = 'high'
                standing_frames += duration_frames
            else:
                current_state = 'low'
                total_low_frames += duration_frames
                if orient == 'down' or ('down' in orient.split('-')):
                    down_frames += duration_frames
                
        elif isinstance(head_y, list) and len(head_y) == 2:  # List of two values case
            if sum(head_y) / len(head_y) > 0.6:
                current_state = 'high'
                standing_frames += duration_frames
            else:
                current_state = 'low'
                total_low_frames += duration_frames
                if orient == 'down' or ('down' in orient.split('-')):
                    down_frames += duration_frames

        # Check if there is a transition from high to low or low to high
        if previous_state and current_state and previous_state != current_state:
            transitions_count += 1
            store_state = previous_state
            store_frames = total_frames
        # Update previous state
        if current_state:
            previous_state = current_state        


        # **è·å–é¢œè‰²**
        color = color_map.get(orient, 'gray')

        # **ç”Ÿæˆ x è½´æ•°æ®**
        x_values = np.arange(start_time, end_time + 1)

        # **ç”Ÿæˆ y è½´æ•°æ®**
        if isinstance(head_y, (int, float)):  # **å•å€¼ï¼Œç»˜åˆ¶æ°´å¹³ç›´çº¿**
            y_values = np.full_like(x_values, head_y, dtype=float)
            head_y_value = head_y

        elif isinstance(head_y, (list, tuple)) and len(head_y) == 2:  # **åŒºé—´å€¼ï¼Œç»˜åˆ¶æŒ¯è¡æ›²çº¿**
            min_val, max_val = head_y
            num_points = len(x_values)
            num_oscillations = 3  # æŒ‡å®šå¾€è¿”çš„æ¬¡æ•°

            # ä¸­é—´å€¼ (èµ·ç‚¹ä¸ç»ˆç‚¹)
            mid_val = (min_val + max_val) / 2
            head_y_value = mid_val

            # è®¡ç®—æ¯æ¬¡å¾€è¿”å ç”¨çš„ç‚¹æ•°ï¼ˆä¸¤ä¸ªæ¥å›ä¸ºä¸€ç»„ï¼‰
            points_per_oscillation = num_points // (num_oscillations * 4)
            
            indices = []
            for _ in range(num_oscillations):
                # ç”Ÿæˆä¸€ä¸ªå®Œæ•´çš„å¾€è¿”ï¼šä¸­é—´å€¼ -> max_val -> ä¸­é—´å€¼ -> min_val -> ä¸­é—´å€¼
                indices.extend(np.linspace(mid_val, max_val, points_per_oscillation))   # ä¸­é—´å€¼ -> æœ€å¤§å€¼
                indices.extend(np.linspace(max_val, mid_val, points_per_oscillation))   # æœ€å¤§å€¼ -> ä¸­é—´å€¼
                indices.extend(np.linspace(mid_val, min_val, points_per_oscillation))   # ä¸­é—´å€¼ -> æœ€å°å€¼
                indices.extend(np.linspace(min_val, mid_val, points_per_oscillation))   # æœ€å°å€¼ -> ä¸­é—´å€¼

            # å¦‚æœç‚¹æ•°ä¸å¤Ÿï¼Œè¡¥ä¸Šä¸­é—´ç‚¹
            if len(indices) < num_points:
                indices = np.concatenate([indices, [mid_val] * (num_points - len(indices))])
            
            y_values = np.array(indices[:num_points])  # ç¡®ä¿ y_values çš„é•¿åº¦ä¸ x_values ä¸€è‡´
                
        else:
            continue  # **æ•°æ®æ ¼å¼é”™è¯¯ï¼Œè·³è¿‡**
        
        plt.plot(x_values, y_values, color=color, linewidth=2, label=orient if orient not in plt.gca().get_legend_handles_labels()[1] else "")
        
        # plt.fill_between(x_values, y_values, 0, color=color, alpha=0.3, label=orient if orient not in plt.gca().get_legend_handles_labels()[1] else "")
        
        # è®¡ç®—å¢å¼ºåçš„é¢œè‰²ï¼Œä½¿å…¶æ›´åŠ é²œè‰³
        enhance_factor = 0.5  # å¯ä»¥è°ƒæ•´è¿™ä¸ªå€¼æ¥æ”¹å˜å¢å¼ºæ•ˆæœ
        original_color = np.array(to_rgb(color))
        enhanced_color = original_color + (1 - original_color) * enhance_factor

        white_color = np.array([1, 1, 1])  # ç™½è‰²

        # å…ˆç”»åº•è‰²å¡«å……åŒºåŸŸ (å¼€å§‹æ˜¯å¢å¼ºçš„é¢œè‰²)
        plt.fill_between(x_values, y_values, 0, color=to_hex(enhanced_color))

        # è®¾ç½®åˆ†å±‚æ•°é‡
        max_y = max(y_values)
        slice_size = 1 / 50  # æ¯æ¬¡å‡å°‘çš„å€¼
        num_slices = int(max_y / slice_size) + 1  # ç”¨æ•´æ•°é™¤æ³•å¹¶åŠ 1ç¡®ä¿å…¨è¦†ç›–
        delta_color = (white_color - enhanced_color) / num_slices  # æ¸å˜æ­¥é•¿

        current_y_values = y_values.copy()

        for slice_index in range(num_slices):
            # è®¡ç®—æ–°çš„é¢œè‰²é€æ­¥å˜ä¸ºç™½è‰²
            current_color = enhanced_color + delta_color * slice_index
            current_color = np.clip(current_color, 0, 1)
            hex_color = to_hex(current_color)

            max_y = max(current_y_values)
            new_y_values = np.where(current_y_values > (max_y - slice_size), max_y - slice_size, current_y_values)
            
            # åªåœ¨å€¼å‡å°‘çš„æƒ…å†µä¸‹ç»˜åˆ¶
            if np.any(new_y_values < current_y_values):
                plt.fill_between(x_values, new_y_values, 0, color=hex_color)
                current_y_values = new_y_values
    

    # **æ·»åŠ å›¾ä¾‹ã€æ ‡ç­¾ã€ç½‘æ ¼**
    plt.rcParams['font.family'] = 'Segoe UI'
    plt.ylim(0, 1)
    plt.xlabel("Frame Index", fontsize=12, color='#525252')
    plt.ylabel("Eye Height (Normalized)", fontsize=12, color='#525252')
    # ax.get_yaxis().set_visible(False)
    ax.yaxis.set_ticks([])
    ax.set_xlim(left=0)
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)
    ax.spines['left'].set_visible(False)
    ax.spines['bottom'].set_visible(False)
    # plt.legend(loc='center left', bbox_to_anchor=(1.01, 0.8), fontsize=12, labelspacing=1.5)

    # ax.xaxis.set_major_locator(plt.MultipleLocator(1000))  # æ¯ 10 å•ä½ç”»ä¸€æ¡ç«–çº¿
    max_x = orientation_segments[-1]["end_frame"]
    for step_size in [1000, 2000, 3000, 4000, 5000]:
        if (max_x / step_size) <= 15:  # ç¡®ä¿æ€»å…±çš„åˆ»åº¦çº¿æ•°é‡ä¸è¶…è¿‡ 15 æ¡
            break
    ax.xaxis.set_major_locator(plt.MultipleLocator(step_size))
    ax.yaxis.set_major_locator(plt.MultipleLocator(0.2))  # æ¯ 0.05 å•ä½ç”»ä¸€æ¡æ¨ªçº¿
    ax.tick_params(axis='x', labelsize=10, labelcolor='#525252')
    ax.tick_params(axis='y', labelsize=10, labelcolor='#525252')
    ax.grid(True, which='major', axis='y', linestyle='--', alpha=0.3)


    # åœ¨å·¦ä¾§æ·»åŠ å›¾ç‰‡
    target_height =  0.79
    target_width = target_height * aspect_ratio
    ax_img1 = fig.add_axes([0.04, 0.09, target_width, target_height], anchor='W')  # ç¡®ä¿å›¾ç‰‡çš„é«˜åº¦ä¸ 0-1 å¯¹é½
    ax_img1.imshow(left_img)
    ax_img1.axis('off')
    ax_img1.set_zorder(0)

    # # è·å–å›¾ç‰‡çš„åŸå§‹åƒç´ å¤§å°
    # img_width, img_height = right_img.size

    # # è·å– fig çš„å¤§å° (å•ä½æ˜¯è‹±å¯¸)
    # fig_width, fig_height = fig.get_size_inches()

    # # å°†å›¾ç‰‡çš„åƒç´ å°ºå¯¸è½¬åŒ–ä¸ºè§„èŒƒåŒ–åæ ‡ (0-1 èŒƒå›´)
    # norm_width = img_width / (fig_width * fig.dpi)
    # norm_height = img_height / (fig_height * fig.dpi)
    # x0, y0, width, height = new_position

    #  # Calculate ratios
    # standing_ratio = standing_frames / total_frames if total_frames > 0 else 0
    # down_ratio = down_frames / total_low_frames if total_low_frames > 0 else 0
    
    # image = []
    # if standing_ratio > 0.8:
    #     new_y = y0 - 0.01 + height *  2 / 3
    #     image.append(1)
    # elif transitions_count > 0:
    #     new_y = y0 - 0.01 + height *  1 / 3
    #     image.append(1)
    # else:
    #     new_y = y0 - 0.01
    #     if down_ratio > 0.8:
    #         image.append(3)
    #     else:
    #         image.append(2)

    # # æ·»åŠ ç¬¬äºŒä¸ªå›¾ç‰‡
    # ax_img2 = fig.add_axes([0.85, new_y, norm_width, norm_height], anchor='W')
    # ax_img2.imshow(right_img)
    # ax_img2.axis('off')
    # ax_img2.set_zorder(0)

    # ä¿å­˜å›¾åƒåˆ°æŒ‡å®šè·¯å¾„
    plt.savefig(save_path)
    plt.close(fig)

def analyze_video_orientation(orientation_segments, fps):
    total_frames = 0
    standing_frames = 0
    down_frames = 0
    transitions_count = 0  # Count of transitions
    total_low_frames = 0  # Total frames where head_y <= 0.6
    store_frames = 0

    # Track the previous state (None means uninitialized)
    previous_state = None  # Can be 'high' (>0.8), 'low' (<0.6), or None
    store_state = None

    for segment in orientation_segments:
        head_y = segment['head_y']
        duration_frames = segment['duration_frames']
        orient = segment['orient']

        # Update total frames
        total_frames += duration_frames

        # Determine the current state based on head_y
        current_state = None

        # Check if head_y is a single value
        if isinstance(head_y, (int, float)):
            if head_y > 0.6:
                current_state = 'high'
                standing_frames += duration_frames
            else:
                current_state = 'low'
                total_low_frames += duration_frames
                if orient == 'down' or ('down' in orient.split('-')):
                    down_frames += duration_frames
                
        elif isinstance(head_y, list) and len(head_y) == 2:  # List of two values case
            if all(value > 0.6 for value in head_y):
                current_state = 'high'
                standing_frames += duration_frames
            else:
                current_state = 'low'
                total_low_frames += duration_frames
                if orient == 'down' or ('down' in orient.split('-')):
                    down_frames += duration_frames

        # Check if there is a transition from high to low or low to high
        if previous_state and current_state and previous_state != current_state:
            transitions_count += 1
            store_state = previous_state
            store_frames = total_frames
        # Update previous state
        if current_state:
            previous_state = current_state        

    # Calculate ratios
    standing_ratio = standing_frames / total_frames if total_frames > 0 else 0
    down_ratio = down_frames / total_low_frames if total_low_frames > 0 else 0

    # Generate result sentences
    image = []
    segment1 = ""
    segment2 = ""
    segment3 = ""
    segment4 = ""
    if standing_ratio > 0.8:
        segment1 = "Height: On Stand"
        segment2 = "The video features standing movements for more than **80%** of its duration. It is recommended to place the playback device on a stand for optimal viewing."
        segment3 = "Orientation: Long Edge Side"
        segment4 = "It is recommended to place the device on one side of the long edge of the yoga mat."
        image.append(1)
    elif transitions_count > 1 :
        segment1 = "Height: > 2 Changes"
        segment2 = "Multiple adjustments to the playback device's height are required."
        segment3 = "Orientation: > 2 Changes"
        segment4 = "Multiple adjustments to the playback device's horizontal position are required."
    elif transitions_count == 1 :
        segment1 = "Height: 1 Change"
        minutes = round(store_frames / fps / 60)
        if store_state == 'high':
            segment2 = f"The first {minutes} minutes of this video consist of standing movements, so it is recommended to place the playback device on a stand. The later part features non-standing movements, for which it is advisable to place the playback device on the floor."
            if down_ratio > 0.8:
                segment3 = "Orientation: 1 Changes"
                segment4 = "It is recommended to place the device along the long edge of the yoga mat at first, and later along the short edge."
                image.append(1)
                image.append(3)
            else:
                segment3 = "Orientation: Long Edge Side"
                segment4 = "It is recommended to place the device along the long edge of the yoga mat."
                image.append(1)
                image.append(2)
        else:
            segment2 = f"The first {minutes} minutes of this video consist of non-standing movements, so it is recommended to place the playback device on the floor. The later part features standing movements, for which it is advisable to place the playback device on a stand."
            if down_ratio > 0.8:
                segment3 = "Orientation: 1 Changes"
                segment4 = "It is recommended to place the device on one side of the short edge of the yoga mat."
                image.append(3)
                image.append(1)
            else:
                segment3 = "Orientation: Long Edge Side"
                segment4 = "It is recommended to place the device along the long edge of the yoga mat."
                image.append(2)
                image.append(1)
    else:
        segment1 = "Height: Floor Level"
        segment2 = "All of the video's duration features non-standing movements, so it is recommended to place the playback device on the floor."
        if down_ratio > 0.8:
            segment3 = "Orientation: Short Edge Side"
            segment4 = ("It is recommended to place the device on one side of the short edge of the yoga mat.")
            image.append(3)
        else:
            segment3 = "Orientation: Long Edge Side"
            segment4 = ("It is recommended to place the device on one side of the long edge of the yoga mat.")
            image.append(2)

    segments = {
        "Segment1": segment1,
        "Segment2": segment2,
        "Segment3": segment3,
        "Segment4": segment4,
    }

    return segments, image

def cal_abs_value(num1, num2):
    return num1 / num2

def plot_orientation_bar_chart(orientation_segments, save_path):
    if not orientation_segments:
        print("é”™è¯¯: orientation_segments ä¸ºç©ºï¼Œæ— æ³•ç»˜åˆ¶æŸ±çŠ¶å›¾ã€‚")
        return

    # æ”¶é›†æ¯ä¸ª orient çš„ç´¯è®¡æ—¶é—´
    orient_times = defaultdict(int)

    for entry in orientation_segments:
        start_time = entry["start_frame"]
        end_time = entry["end_frame"]
        orient = entry["orient"]
        duration = end_time - start_time + 1

        orient_times[orient] += duration

    total_frames = orientation_segments[-1]["end_frame"]
    sorted_orients = sorted(orient_times.items(), key=lambda x: x[1], reverse=False)
    orients = [item[0] for item in sorted_orients]
    times = [item[1] for item in sorted_orients]
    percentages = [round((time / total_frames) * 100) for time in times]

    # å®šä¹‰é¢œè‰²æ˜ å°„
    color_map = {
        'neutral': '#59C9A5',
        # 'right': '#ffffb3',
        'up': '#FC9F5B',
        'down': '#D7B9D5',
        'neutral-down': '#1E96FC',
        'neutral-up': '#b3de69',
        'down-up': '#DE425B',
    }
    colors = [color_map.get(orient, 'gray') for orient in orients]

    bar_height = 60
    bar_spacing = 20

    target_width_px = 1280
    if len(orients) == 1 :
        target_height_px =  bar_height + 20
    else: 
        target_height_px = bar_height * len(orients) + bar_spacing * (len(orients) - 1) + 20
    dpi = 100
    fig_width, fig_height = target_width_px / dpi, target_height_px / dpi
    fig, ax = plt.subplots(figsize=(fig_width, fig_height))
    original_position = ax.get_position()  # è·å– ax çš„ä½ç½®ä¿¡æ¯
    new_position = [original_position.x0 + 0.05, original_position.y0 + 0.05,
                original_position.width, original_position.height]
    ax.set_position(new_position)


    plt.rcParams['font.family'] = 'Segoe UI'
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)
    ax.spines['left'].set_visible(False)
    ax.spines['bottom'].set_visible(False)
    ax.get_xaxis().set_visible(False)


    y_positions = []

    for i, (orient_name, color) in enumerate(zip(orients, colors)):
        y_pos1 = cal_abs_value(10 + i * (bar_height + bar_spacing), target_height_px)
        y_pos2 = cal_abs_value(10 + i * (bar_height + bar_spacing) + 2, target_height_px)
        y_pos3 = cal_abs_value(10 + i * (bar_height + bar_spacing) + 30, target_height_px)
        y_positions.append(cal_abs_value(40 + i * (bar_height + bar_spacing), target_height_px))

        fancy_box = FancyBboxPatch(
            xy=(0.015, y_pos1),               # çŸ©å½¢çš„å·¦ä¸‹è§’ä½ç½®
            width=0.924,                   # å®½åº¦
            height=cal_abs_value(bar_height, target_height_px), 
            boxstyle="round,pad=0.01",      # çŸ©å½¢æ ·å¼ä¸ºåœ†è§’ï¼Œå¸¦æœ‰å†…è¾¹è·        
            facecolor=color,       # å¡«å……é¢œè‰²
            linewidth=0,                 # è¾¹æ¡†å®½åº¦
            mutation_scale=1.5,          # åœ†è§’çš„ç¼©æ”¾æ¯”ä¾‹
            alpha=0.3                    # é€æ˜åº¦
        )
        ax.add_patch(fancy_box)
        # ax.text(0.9, y_pos3, times[i], fontsize=14, ha='center', va='center', color=color)

        fancy_box = FancyBboxPatch(
            xy=(0.015, y_pos2),               # çŸ©å½¢çš„å·¦ä¸‹è§’ä½ç½®
            width=cal_abs_value(times[i], total_frames) * 0.9,  
            height=cal_abs_value(bar_height*0.95, target_height_px),                  # é«˜åº¦
            boxstyle="round,pad=0.01",   # çŸ©å½¢æ ·å¼ä¸ºåœ†è§’ï¼Œå¸¦æœ‰å†…è¾¹è·
            facecolor=color,       # å¡«å……é¢œè‰²
            linewidth=0,                 # è¾¹æ¡†å®½åº¦
            mutation_scale=1.5,          # åœ†è§’çš„ç¼©æ”¾æ¯”ä¾‹
            alpha= 1                  # é€æ˜åº¦
        )
        # ax.text(cal_abs_value(times[i], total_frames) * 0.9 + 0.08, y_pos3, f'{percentages[i]}%', fontsize=14, ha='center', va='center', color="black")
        ax.text(0.9, y_pos3, f'{percentages[i]}%', fontsize=14, ha='center', va='center', color=color)
        ax.add_patch(fancy_box)

            # æ·»åŠ å›¾ç‰‡
        images_to_add = []
        if '-' in orient_name:
            words = orient_name.split('-')
            images_to_add = words  # åˆ†å‰²åçš„æ¯ä¸ªå•è¯éƒ½ä»£è¡¨ä¸€ä¸ªå›¾ç‰‡
        else:
            images_to_add = [orient_name]  # å•ä¸ªè¯æ ‡ç­¾
        
        # æ·»åŠ å›¾ç‰‡
        for i, word in enumerate(images_to_add):
            image_path = os.path.join(IMAGE_FOLDER, f'{word}.png')
            if os.path.exists(image_path):  # ç¡®ä¿å›¾ç‰‡å­˜åœ¨
                img = Image.open(image_path)
                imagebox = OffsetImage(img)
                if len(images_to_add) == 1:
                    ab = AnnotationBbox(imagebox, (0.01, y_pos3), 
                                    frameon=False, xycoords='axes fraction', box_alignment=(0, 0.5))
                else:
                    ab = AnnotationBbox(imagebox, (0.01 + 0.04 * i, y_pos3), 
                                    frameon=False, xycoords='axes fraction', box_alignment=(0, 0.5))
                ax.add_artist(ab)
        

    ax.set_yticks(y_positions)
    orients = [label.capitalize() for label in orients]
    ax.set_yticklabels(orients)
    ax.tick_params(axis='y', labelsize=12, labelcolor='#525252')

    # ä¿å­˜å¹¶å…³é—­å›¾è¡¨
    plt.savefig(save_path)
    plt.close(fig)


if __name__ == "__main__":

    filename="tv6.json"
    fps, people_counts, body_height, orientation, head_y = load_json_data(filename)
    

    people_counts, orientation = smooth_stable_data(people_counts, orientation)
    orientation_segments = first_orientation_segments(orientation, body_height, head_y, fps)
    orientation_segments, orientation, body_height, head_y = filter_invalid_orientation_segments(orientation_segments, orientation, body_height, head_y, fps)
    
    change_points = detect_change_points(body_height, visualize=False)
    orientation_segments, orientation, body_height, head_y = remove_large_height_changes(change_points, orientation_segments, orientation, body_height, head_y, fps)
    orientation_segments = merge_alternating_orients(orientation_segments, fps)
    orientation_segments, orientation, body_height, head_y = merge_orientation_segments(orientation_segments, orientation, body_height, head_y, fps)


    segmented_head_y = split_head_y_by_orientation(orientation_segments, head_y)
    segmented_head_y, split_info = process_segmented_head_y(segmented_head_y)

    periodics = []
    means = []
    amps = []
    for segment in segmented_head_y:
        segment = np.array(segment, dtype=float)
        periodic, mean, amp = detect_periodicity_acf_with_peaks(segment)
        if periodic:
            if amp < 0.05:
                periodic = False
        periodics.append(periodic)
        means.append(mean)
        amps.append(amp)
    
    orientation_segments = split_orientation_segments(orientation_segments, segmented_head_y, split_info)
    orientation_segments = update_orientation_segments(orientation_segments, periodics, means, amps)


    IMAGE_FOLDER = "MoveMate/static/images"
    if not os.path.exists(IMAGE_FOLDER):
        os.makedirs(IMAGE_FOLDER)

    image_path_1 = os.path.join(IMAGE_FOLDER, 'result_plot_1.png')
    image_path_2 = os.path.join(IMAGE_FOLDER, 'result_plot_2.png')
    


    plot_orientation_segments(orientation_segments, image_path_1)
    plot_orientation_bar_chart(orientation_segments, image_path_2)
    segments, image = analyze_video_orientation(orientation_segments, fps)
    print(segments)



    image_urls = {}
    image_urls[f"image_url_1"] = "/" + image_path_1 if image_path_1 else None
    image_urls[f"image_url_2"] = "/" + image_path_2 if image_path_2 else None
    image_urls["image_url1"] = None
    image_urls["image_url2"] = None
    i = 1
    for index, img in enumerate(image, start=1):  # ä»1å¼€å§‹ç¼–å·
        if img == 1:
            image_urls[f"image_url{i}"] = "/" + os.path.join(IMAGE_FOLDER, '1.png')
            i += 1
        elif img == 2:
            image_urls[f"image_url{i}"] = "/" + os.path.join(IMAGE_FOLDER, '2.png')
            i += 1
        elif img == 3:
            image_urls[f"image_url{i}"] = "/" + os.path.join(IMAGE_FOLDER, '3.png')

    # æ„å»ºè¿”å›çš„ JSON æ•°æ®
    response_data = {
        "done": True
    }
    response_data.update(segments)
    response_data.update(image_urls)  # æ·»åŠ å›¾ç‰‡ URL é”®å€¼å¯¹


    print(orientation_segments)
    
    # plot_orientation_segments_with_images(orientation_segments)
    
    # plot_combined_single_axis(head_y, orientation_segments)


    

#     if previous_orient is None:  # åˆå§‹çŠ¶æ€
    #         accumulated_start_time = start_time
    #         accumulated_end_time = end_time
    #         accumulated_y_values = y_values
    #     elif orient == previous_orient:  # è¿ç»­ç›¸åŒçš„ orient
    #         accumulated_end_time = end_time
    #         accumulated_y_values = np.concatenate((accumulated_y_values, y_values))
    #     else:  # ä¸åŒçš„ orientï¼Œè¿›è¡Œæ–‡æœ¬ç»˜åˆ¶
    #         mid_x = (accumulated_start_time + accumulated_end_time) / 2
    #         mid_y = max(accumulated_y_values) + 0.03

    #         if '-' in previous_orient:  # å¦‚æœæ˜¯è¿æ¥è¯
    #             word1, word2 = previous_orient.split('-')
    #             plt.text(mid_x, mid_y + 0.04, word1, fontsize=12, ha='center', va='bottom', color='black')
    #             plt.text(mid_x, mid_y, f'&{word2}', fontsize=12, ha='center', va='bottom', color='black')
    #         else:  # å¦‚æœæ˜¯å•è¯
    #             plt.text(mid_x, mid_y, previous_orient, fontsize=12, ha='center', va='bottom', color='black')

    #         # é‡ç½®ç§¯ç´¯çš„å€¼
    #         accumulated_start_time = start_time
    #         accumulated_end_time = end_time
    #         accumulated_y_values = y_values

    #     previous_orient = orient  # æ›´æ–°å½“å‰çš„ orient

    #     # **åœ¨ orientation ç‰‡æ®µé¡¶éƒ¨æ ‡æ³¨ orient**
    #     # mid_x = (start_time + end_time) / 2
    #     # mid_y = max(y_values) + 0.03  # **è®©æ–‡æœ¬ç¨å¾®é«˜äºæ›²çº¿**
    #     # if '-' in orient:  # å¦‚æœæ˜¯è¿æ¥è¯
    #     #     word1, word2 = orient.split('-')
    #     #     plt.text(mid_x, mid_y + 0.04, word1, fontsize=12, ha='center', va='bottom', color='black')
    #     #     plt.text(mid_x, mid_y, f'&{word2}', fontsize=12, ha='center', va='bottom', color='black')
    #     # else:  # å¦‚æœæ˜¯å•è¯
    #     #     plt.text(mid_x, mid_y, orient, fontsize=12, ha='center', va='bottom', color='black')
    
    # if previous_orient is not None:
    #     mid_x = (accumulated_start_time + accumulated_end_time) / 2
    #     mid_y = max(accumulated_y_values) + 0.03

    #     if '-' in previous_orient:  
    #         word1, word2 = previous_orient.split('-')
    #         plt.text(mid_x, mid_y + 0.04, word1, fontsize=12, ha='center', va='bottom', color='black')
    #         plt.text(mid_x, mid_y, f'&{word2}', fontsize=12, ha='center', va='bottom', color='black')
    #     else:
    #         plt.text(mid_x, mid_y, previous_orient, fontsize=12, ha='center', va='bottom', color='black')


# body_height = smooth_body_height(body_height, fps)
# orientation_segments = merge_RL_orientation_segments(orientation_segments, fps)


# def smooth_body_height(body_height, fps=30, min_duration_sec=2, window_size=5):
#     """
#     å¹³æ»‘ body_height æ•°æ®ï¼Œæ£€æµ‹å¹¶ä¿®æ­£çªå˜ç‚¹ï¼ˆåŒ…å«çªç„¶å˜å¤§å’Œçªç„¶å˜å°çš„æƒ…å†µï¼‰ã€‚
    
#     ä¸»è¦é€»è¾‘ï¼š
#     1. è®¡ç®—è‡ªé€‚åº”é˜ˆå€¼ thresholdï¼Œç”¨äºæ£€æµ‹ body_height çš„çªå˜åŒºåŸŸã€‚
#     2. éå†æ•°æ®ï¼Œæ£€æµ‹çªå˜ï¼š
#        - å¦‚æœå½“å‰å€¼ä¸å‰ä¸€ä¸ªå€¼çš„å·®å¼‚è¶…è¿‡ thresholdï¼Œåˆ™æ ‡è®°ä¸ºçªå˜ç‚¹ã€‚
#        - æ‰¾åˆ°çªå˜åŒºé—´çš„èµ·ç‚¹å’Œç»ˆç‚¹ã€‚
#        - å¦‚æœçªå˜åŒºé—´çš„æŒç»­æ—¶é—´å°äº `min_duration_sec`ï¼Œåˆ™è¿›è¡Œä¿®æ­£ã€‚
#     3. ä¿®æ­£æ–¹æ³•ï¼š
#        - è®¡ç®—çªå˜åŒºé—´å‰å `window_size` ä»¥å†…çš„æ•°æ®çš„å¹³å‡å€¼ã€‚
#        - ç”¨è®¡ç®—å¾—åˆ°çš„å±€éƒ¨å‡å€¼æ›¿æ¢çªå˜åŒºé—´å†…çš„å€¼ï¼Œä½¿æ•°æ®å¹³æ»‘ã€‚

#     å‚æ•°ï¼š
#         body_height (list[float]): éœ€è¦å¹³æ»‘çš„ body_height æ•°æ®åˆ—è¡¨ã€‚
#         fps (int): æ¯ç§’å¸§æ•° (é»˜è®¤ 30)ã€‚
#         method (str): è®¡ç®—è‡ªé€‚åº”é˜ˆå€¼çš„æ–¹æ³•ï¼ˆ"std", "mad", "iqr"ï¼‰ï¼Œé»˜è®¤ "std"ã€‚
#         k (float): è®¡ç®—é˜ˆå€¼æ—¶çš„ä¹˜æ•°å› å­ï¼Œæ§åˆ¶æ•æ„Ÿåº¦ (é»˜è®¤ 2)ã€‚
#         min_duration_sec (int): æœ€å°çªå˜æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œä½äºè¯¥æ—¶é—´çš„çªå˜åŒºé—´ä¼šè¢«ä¿®æ­£ (é»˜è®¤ 2)ã€‚
#         window_size (int): è®¡ç®—å±€éƒ¨å‡å€¼æ—¶çš„çª—å£å¤§å° (é»˜è®¤ 5)ã€‚

#     è¿”å›ï¼š
#         list[float]: å¹³æ»‘åçš„ body_height æ•°æ®ã€‚

#     """
#     # è®¡ç®—çªå˜çš„æœ€å°æŒç»­æ—¶é—´ï¼ˆå¸§æ•°ï¼‰
#     min_duration = fps * min_duration_sec
    
#     # å¤åˆ¶åŸå§‹æ•°æ®ï¼Œé¿å…ä¿®æ”¹è¾“å…¥åˆ—è¡¨
#     smoothed_body_height = body_height.copy()
#     n = len(body_height)

#     # è®¡ç®—è‡ªé€‚åº” thresholdï¼Œç”¨äºæ£€æµ‹çªå˜
#     threshold = compute_adaptive_threshold(body_height)

#     # éå†æ•°æ®ï¼Œæ£€æµ‹å¹¶ä¿®æ­£çªå˜
#     i = 1  # ä»ç´¢å¼•1å¼€å§‹éå†ï¼Œé¿å…è®¿é—®è´Ÿç´¢å¼•

#     while i < n - 1:
#         prev_height = body_height[i - 1]
#         current_height = body_height[i]

#         # æ£€æµ‹ body_height çš„çªå˜ç‚¹
#         if abs(current_height - prev_height) > threshold:
#             start_idx = i  # è®°å½•çªå˜åŒºé—´çš„èµ·ç‚¹

#             # æ‰¾åˆ°çªå˜åŒºé—´ç»ˆç‚¹ï¼ˆæ•°æ®æ¢å¤åˆ°åŸå€¼åŸŸï¼‰
#             while i < n - 1 and abs(body_height[i] - prev_height) > threshold:
#                 i += 1
            
#             end_idx = i  # è®°å½•çªå˜åŒºé—´ç»ˆç‚¹

#             # å¦‚æœçªå˜åŒºé—´çš„æŒç»­æ—¶é—´å°äº `min_duration`ï¼Œåˆ™è¿›è¡Œå¹³æ»‘å¤„ç†
#             if (end_idx - start_idx) < min_duration:
#                 # è®¡ç®—å±€éƒ¨å‡å€¼ï¼ˆä½¿ç”¨å‰ `window_size` ä¸ªç‚¹ + å `window_size` ä¸ªç‚¹ï¼‰
#                 window_start = max(0, start_idx - window_size)
#                 window_end = min(n, end_idx + window_size + 1)
#                 local_avg = sum(body_height[window_start:window_end]) / (window_end - window_start)

#                 # æ›¿æ¢çªå˜åŒºé—´çš„å€¼ï¼Œä½¿æ•°æ®å¹³æ»‘
#                 for j in range(start_idx, end_idx):
#                     smoothed_body_height[j] = local_avg

#                 print(f"Smoothed spike from index {start_idx} to {end_idx - 1}: replaced with {local_avg}")

#         i += 1  # ç»§ç»­éå†æ•°æ®

#     return smoothed_body_height


# def merge_RL_orientation_segments(orientation_segments, fps=30, min_duration_sec=3, max_duration_sec=15):
#     """
#     åˆå¹¶ç›¸é‚»çš„ 'right' å’Œ 'left' æ–¹å‘ç‰‡æ®µï¼Œä»¥å‡å°‘çŸ­æ—¶æ³¢åŠ¨ã€‚

#     ä¸»è¦é€»è¾‘ï¼š
#     1. **éå†æ‰€æœ‰ç‰‡æ®µ**ï¼š
#        - å¦‚æœå½“å‰ç‰‡æ®µçš„æ–¹å‘æ˜¯ `'right'` æˆ– `'left'`ï¼Œåˆ™æ£€æŸ¥æ˜¯å¦èƒ½ä¸åç»­ç›¸åŒæ–¹å‘çš„ç‰‡æ®µåˆå¹¶ã€‚
#     2. **æ£€æŸ¥åˆå¹¶æ¡ä»¶**ï¼š
#        - å¦‚æœåç»­ç‰‡æ®µä¸å½“å‰æ–¹å‘ç›¸åŒï¼Œåˆ™ç»§ç»­æ‰©å±•åˆå¹¶åŒºé—´ã€‚
#        - å¦‚æœé‡åˆ°ä¸åŒæ–¹å‘çš„ç‰‡æ®µï¼Œä¸”å…¶ `duration_frames` è¶…è¿‡ `min_duration_frames`ï¼Œåˆ™åœæ­¢åˆå¹¶ã€‚
#     3. **è®¡ç®—åˆå¹¶æ¡ä»¶**ï¼š
#        - è‹¥åˆå¹¶åè¯¥æ–¹å‘çš„æ€»å¸§æ•°å¤§äº `total_frames / 2`ï¼Œä¸”æ€»æ—¶é•¿è¶…è¿‡ `max_duration_frames`ï¼Œåˆ™åˆå¹¶ã€‚
#     4. **æ ‡è®°å·²åˆå¹¶çš„ç‰‡æ®µ**ï¼š
#        - è®°å½• `start_frame` ä»¥é¿å…é‡å¤åˆå¹¶ã€‚
#     5. **æ£€æŸ¥æœªåˆå¹¶çš„ 'right' å’Œ 'left' ç‰‡æ®µ**ï¼š
#        - å¦‚æœæŸä¸ªç‰‡æ®µæœªè¢«åˆå¹¶ï¼Œåˆ™å°†å…¶æ›´æ”¹ä¸º `'neutral'`ï¼Œé¿å…çŸ­æ—¶æ³¢åŠ¨ã€‚

#     å‚æ•°ï¼š
#         orientation_segments (list[dict]): å§¿æ€ä¿¡æ¯ç‰‡æ®µï¼Œæ¯ä¸ªç‰‡æ®µæ˜¯ä¸€ä¸ªå­—å…¸ã€‚
#         fps (int): è§†é¢‘çš„å¸§ç‡ï¼ˆé»˜è®¤ 30ï¼‰ã€‚
#         min_duration_sec (int): æœ€å°æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œå°äºè¯¥å€¼çš„ç‰‡æ®µä¸ä¼šå•ç‹¬ä¿ç•™ï¼ˆé»˜è®¤ 3 ç§’ï¼‰ã€‚
#         max_duration_sec (int): æœ€å¤§åˆå¹¶æ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œè¶…è¿‡è¯¥å€¼çš„ç‰‡æ®µæ‰ä¼šåˆå¹¶ï¼ˆé»˜è®¤ 15 ç§’ï¼‰ã€‚

#     è¿”å›ï¼š
#         list[dict]: å¤„ç†åçš„ `orientation_segments` ç‰‡æ®µåˆ—è¡¨ã€‚
#     """

#     # è®¡ç®—æœ€å°å’Œæœ€å¤§å…è®¸çš„å¸§æ•°
#     min_duration_frames = fps * min_duration_sec
#     max_duration_frames = fps * max_duration_sec

#     merged_segments = []  # å­˜å‚¨åˆå¹¶åçš„ç‰‡æ®µ
#     i = 0
#     merged_right_left_frames = set()  # è®°å½•å·²åˆå¹¶çš„ç‰‡æ®µ `start_frame`ï¼Œé˜²æ­¢ç´¢å¼•å¤±æ•ˆ

#     while i < len(orientation_segments):
#         segment = orientation_segments[i]
#         orient = segment['orient']

#         # ä»…å¤„ç† 'right' æˆ– 'left' æ–¹å‘
#         if orient in ('right', 'left'):
#             j = i + 1
#             last_matching_index = i  # è®°å½•æœ€åä¸€ä¸ªåŒ¹é…ç‰‡æ®µçš„ç´¢å¼•

#             while j < len(orientation_segments):
#                 next_segment = orientation_segments[j]
#                 if next_segment['orient'] == orient:
#                     last_matching_index = j  # ç»§ç»­æ‰©å±•åˆå¹¶åŒºé—´

#                 # å¦‚æœé‡åˆ°ä¸åŒæ–¹å‘çš„ç‰‡æ®µï¼Œä¸”æ—¶é•¿å¤§äº `min_duration_frames`ï¼Œåˆ™åœæ­¢åˆå¹¶
#                 if next_segment['orient'] != orient and next_segment['duration_frames'] > min_duration_frames:
#                     break
                
#                 j += 1  # ç¡®ä¿ j é€’å¢ï¼Œé¿å…æ­»å¾ªç¯

#             # è·å–æ‰€æœ‰å¾…åˆå¹¶çš„ç‰‡æ®µ
#             collected_segments = [orientation_segments[k] for k in range(i, last_matching_index + 1)]
#             orient_frames = sum(seg['duration_frames'] for seg in collected_segments if seg['orient'] == orient)
#             total_frames = sum(seg['duration_frames'] for seg in collected_segments)

#             # å¦‚æœåˆå¹¶åç¬¦åˆæ¡ä»¶ï¼Œåˆ™åˆå¹¶
#             if orient_frames > total_frames / 2 and total_frames > max_duration_frames:
#                 merged_segment = {
#                     'orient': orient,
#                     'start_frame': collected_segments[0]['start_frame'],
#                     'end_frame': collected_segments[-1]['end_frame'],
#                     'duration_sec': sum(seg['duration_sec'] for seg in collected_segments),
#                     'duration_frames': total_frames
#                 }
#                 merged_segments.append(merged_segment)
                
#                 # è®°å½•åˆå¹¶ç‰‡æ®µçš„ `start_frame`ï¼Œé¿å…ç´¢å¼•å¤±æ•ˆ
#                 merged_right_left_frames.update(seg['start_frame'] for seg in collected_segments)
                
#                 i = last_matching_index + 1  # è·³è¿‡åˆå¹¶çš„ç‰‡æ®µ
#             else:
#                 # ä¸ç¬¦åˆåˆå¹¶æ¡ä»¶ï¼Œç›´æ¥æ·»åŠ 
#                 merged_segments.append(segment)
#                 i += 1
#         else:
#             # é 'right' æˆ– 'left' ç‰‡æ®µï¼Œç›´æ¥æ·»åŠ 
#             merged_segments.append(segment)
#             i += 1

#     # ä¿®æ­£é€»è¾‘ï¼šæ£€æŸ¥ `merged_segments`ï¼Œè‹¥ç‰‡æ®µæœªåˆå¹¶ï¼Œåˆ™æ”¹ä¸º 'neutral'
#     for segment in merged_segments:
#         if segment['orient'] in ('right', 'left') and segment['start_frame'] not in merged_right_left_frames:
#             segment['orient'] = 'neutral'

#     return merged_segments


 # è‡ªå®šä¹‰å›¾ä¾‹ä½ç½®
    # legend_labels = list(labels_used)
    # spacing_between_labels = 0.15  # æ¯ä¸ªæ ‡ç­¾çš„ä¸Šä¸‹è·ç¦»å¢å¤§
    # legend_positions = [(1.03, 0.95 - i * spacing_between_labels) for i in range(len(legend_labels))] 

    # for label, pos in zip(legend_labels, legend_positions):
    #     color = color_map.get(label, 'gray')
        
    #     # æ·»åŠ é¢œè‰²çŸ©å½¢
    #     rect = Rectangle((pos[0] - 0.015, pos[1] - 0.015), 0.01, 0.03, 
    #                      transform=ax.transAxes, color=color, clip_on=False, alpha=0.5)
    #     ax.add_patch(rect)
        
    #     # æ·»åŠ æ ‡ç­¾æ–‡å­—
    #     ax.text(pos[0], pos[1], label, transform=ax.transAxes, fontsize=12, va='center', ha='left')
        
    #     # æ·»åŠ å›¾ç‰‡
    #     images_to_add = []
    #     if '-' in label:
    #         words = label.split('-')
    #         images_to_add = words  # åˆ†å‰²åçš„æ¯ä¸ªå•è¯éƒ½ä»£è¡¨ä¸€ä¸ªå›¾ç‰‡
    #     else:
    #         images_to_add = [label]  # å•ä¸ªè¯æ ‡ç­¾
        
    #     # æ·»åŠ å›¾ç‰‡
    #     for i, word in enumerate(images_to_add):
    #         image_path = os.path.join(IMAGE_FOLDER, f'{word}.png')
    #         if os.path.exists(image_path):  # ç¡®ä¿å›¾ç‰‡å­˜åœ¨
    #             img = Image.open(image_path)
    #             imagebox = OffsetImage(img)
    #             if len(images_to_add) == 1:
    #                 ab = AnnotationBbox(imagebox, (pos[0] + 0.06 + 0.05 * i, pos[1]), 
    #                                 frameon=False, xycoords='axes fraction')
    #             else:
    #                 ab = AnnotationBbox(imagebox, (pos[0] + 0.09 + 0.04 * i, pos[1]), 
    #                                 frameon=False, xycoords='axes fraction')
    #             ax.add_artist(ab)

    # def plot_orientation_bar_chart(orientation_segments, save_path):
#     if not orientation_segments:
#         print("é”™è¯¯: orientation_segments ä¸ºç©ºï¼Œæ— æ³•ç»˜åˆ¶æŸ±çŠ¶å›¾ã€‚")
#         return

#     # æ”¶é›†æ¯ä¸ª orient çš„ç´¯è®¡æ—¶é—´
#     orient_times = defaultdict(int)

#     for entry in orientation_segments:
#         start_time = entry["start_frame"]
#         end_time = entry["end_frame"]
#         orient = entry["orient"]
#         duration = end_time - start_time + 1

#         orient_times[orient] += duration

#     total_frames = orientation_segments[-1]["end_frame"]
#     sorted_orients = sorted(orient_times.items(), key=lambda x: x[1], reverse=False)
#     orients = [item[0] for item in sorted_orients]
#     times = [item[1] for item in sorted_orients]
#     percentages = [round((time / total_frames) * 100) for time in times]

#     # å®šä¹‰é¢œè‰²æ˜ å°„
#     color_map = {
#         'neutral': '#8dd3c7',
#         'up': '#fb8072',
#         'down': '#bebada',
#         'neutral-down': '#fdb462',
#         'neutral-up': '#b3de69',
#         'down-up': '#fccde5',
#     }
#     colors = [color_map.get(orient, 'gray') for orient in orients]

#     # åˆ›å»ºå›¾è¡¨
#     target_width_px = 1000
#     target_height_px = 120 * len(orients) + 50
#     dpi = 100
#     fig_width, fig_height = target_width_px / dpi, target_height_px / dpi
#     fig, ax = plt.subplots(figsize=(fig_width, fig_height))
#     original_position = ax.get_position()  # è·å– ax çš„ä½ç½®ä¿¡æ¯
#     new_position = [original_position.x0 + 0.01, original_position.y0 + 0.05,
#                 original_position.width, original_position.height]
#     ax.set_position(new_position)


#     plt.rcParams['font.family'] = 'Segoe UI'
#     ax.spines['top'].set_visible(False)
#     ax.spines['right'].set_visible(False)
#     ax.spines['left'].set_visible(False)
#     ax.spines['bottom'].set_visible(False)
#     ax.get_xaxis().set_visible(False)

#     target_height_px = 100
#     data_height = fig_height * dpi
#     spacing_factor = 1
#     height_spacing = (target_height_px / data_height) * len(orients) * spacing_factor
#     height  = height_spacing * 0.7

#     y_poss = []

#     for i, (orient_name, color) in enumerate(zip(orients, colors)):
#         y_pos = float(i * height_spacing)
#         y_poss.append(y_pos)
#         rgba_color = np.array(to_rgb(color) + (0.2,))  # æ·»åŠ é€æ˜åº¦

#         ax.barh(y_pos, total_frames, color=rgba_color, height=height)
#         ax.barh(y_pos, times[i], color=color, height=height * 0.85)

#         ax.text(times[i] * 1.05, y_pos, f'{percentages[i]}%',
#                 va='center', ha='left', fontsize=14, color='black') 
#         ax.text(total_frames * 0.92, y_pos, f'{times[i]}',
#                 va='center', ha='left', fontsize=14, color=color)
        
#         # images = []
#         # total_width = 0
#         # for part in orient_name.split('-'):
#         #     img_path = os.path.join(IMAGE_FOLDER, f'{part}.png')
#         #     if os.path.exists(img_path):
#         #         img = Image.open(img_path)
#         #         images.append(img)
#         #         total_width += img.width

#         # if images:  # å¦‚æœæœ‰åŠ è½½åˆ°çš„å›¾ç‰‡
#         #     x_offset = -total_width - 5  # æ”¾åœ¨æŸ±å­å·¦è¾¹
#         #     y_offset = y_pos - height / 2  # ç”¨ i è€Œä¸æ˜¯ y_pos
#         #     for img in images:
#         #         img_width, img_height = img.size
#         #         ax.imshow(img, extent=[x_offset, x_offset + img_width, y_offset, y_offset + height], aspect='auto')
#         #         x_offset += img_width

#     ax.set_yticks(y_poss)
#     ax.set_yticklabels(orients)
#     ax.tick_params(axis='y', labelsize=14)

#     # ä¿å­˜å¹¶å…³é—­å›¾è¡¨
#     plt.savefig(save_path)
#     plt.close(fig)