import cv2
import dlib
import numpy as np

# 1ï¸âƒ£ åŠ è½½ Dlib é¢„è®­ç»ƒæ¨¡å‹ï¼ˆç”¨äºäººè„¸æ£€æµ‹ + 68 å…³é”®ç‚¹æå–ï¼‰
detector = dlib.get_frontal_face_detector()  # äººè„¸æ£€æµ‹å™¨
predictor = dlib.shape_predictor("shape_predictor_68_face_landmarks.dat")  # å…³é”®ç‚¹æ£€æµ‹æ¨¡å‹

# 2ï¸âƒ£ å®šä¹‰ 3D å‚è€ƒç‚¹ï¼ˆç”¨äºå¤´éƒ¨å§¿æ€ä¼°è®¡ï¼‰
MODEL_3D_POINTS = np.array([
    (0.0, 0.0, 0.0),  # é¼»å°–
    (-30.0, -70.0, -50.0),  # å·¦çœ¼è§’
    (30.0, -70.0, -50.0),  # å³çœ¼è§’
    (-60.0, -40.0, -50.0),  # å·¦å˜´è§’
    (60.0, -40.0, -50.0),  # å³å˜´è§’
    (0.0, -110.0, -65.0),  # ä¸‹å·´
    (0.0, 40.0, -60.0)  # é¢å¤´ï¼ˆçœ‰å¿ƒï¼‰
], dtype=np.float32)


def process_frame(image):
    """
    å¤„ç†å•å¸§å›¾åƒï¼Œæ£€æµ‹äººè„¸å¹¶ä¼°ç®—å¤´éƒ¨å§¿æ€ã€‚
    :param image: è¾“å…¥å›¾åƒï¼ˆnumpy æ•°ç»„ï¼‰
    :return: å¤„ç†åçš„å›¾åƒï¼ˆå¸¦æ£€æµ‹ç»“æœï¼‰
    """
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # è½¬æ¢ä¸ºç°åº¦å›¾ï¼Œæé«˜æ£€æµ‹ç²¾åº¦
    faces = detector(gray)  # æ£€æµ‹æ‰€æœ‰äººè„¸

    if len(faces) == 0:
        # âŒ æ²¡æœ‰æ£€æµ‹åˆ°äººè„¸ï¼Œåœ¨ç”»é¢ä¸Šæ˜¾ç¤º "No Face Detected"
        image = cv2.putText(image, "No Face Detected", (50, 100), 
                            cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255, 0, 255), 3)
        return image  # ç›´æ¥è¿”å›å›¾åƒ

    for face in faces:
        landmarks = predictor(gray, face)  # æå– 68 ä¸ªäººè„¸å…³é”®ç‚¹

        # æå– 2D å…³é”®ç‚¹ï¼ˆç”¨äºè®¡ç®—å¤´éƒ¨å§¿æ€ï¼‰
        image_points = np.array([
            (landmarks.part(30).x, landmarks.part(30).y),  # é¼»å°–
            (landmarks.part(36).x, landmarks.part(36).y),  # å·¦çœ¼è§’
            (landmarks.part(45).x, landmarks.part(45).y),  # å³çœ¼è§’
            (landmarks.part(48).x, landmarks.part(48).y),  # å·¦å˜´è§’
            (landmarks.part(54).x, landmarks.part(54).y),  # å³å˜´è§’
            (landmarks.part(8).x, landmarks.part(8).y),  # ä¸‹å·´
            (landmarks.part(27).x, landmarks.part(27).y)  # é¢å¤´ï¼ˆçœ‰å¿ƒï¼‰
        ], dtype=np.float32)

        # è®¡ç®— 3D å¤´éƒ¨å§¿æ€
        _, rotation_vec, _ = cv2.solvePnP(MODEL_3D_POINTS, image_points, np.eye(3), None, flags=cv2.SOLVEPNP_EPNP)

        # æå– Yaw è§’åº¦ï¼ˆåèˆªè§’ï¼Œç”¨äºåˆ¤æ–­æ˜¯å¦ç›´é¢æ‘„åƒå¤´ï¼‰
        yaw = rotation_vec[1] * (180 / np.pi)  # è½¬æ¢ä¸ºè§’åº¦åˆ¶

        # è°ƒæ•´é˜ˆå€¼ï¼Œä½¿å¾—æ£€æµ‹æ›´ç¨³å®š
        if -20 < yaw < 20:  # æ”¾å®½é˜ˆå€¼ï¼Œé¿å…è¯¯åˆ¤
            text = "Facing Camera"
            color = (0, 255, 0)  # ç»¿è‰²
        else:
            text = "Not Facing Camera"
            color = (0, 0, 255)  # çº¢è‰²

        # åœ¨å›¾åƒä¸Šç»˜åˆ¶æ£€æµ‹ç»“æœ
        image = cv2.putText(image, text, (25, 100), cv2.FONT_HERSHEY_SIMPLEX, 1.25, color, 3)

    return image  # è¿”å›å¤„ç†åçš„å›¾åƒ


def generate_video(input_video_path, output_video_path):
    """
    å¤„ç†æ•´ä¸ªè§†é¢‘ï¼Œå¹¶ä¿å­˜å¸¦æ£€æµ‹ç»“æœçš„è§†é¢‘ã€‚
    :param input_video_path: è¾“å…¥è§†é¢‘è·¯å¾„
    :param output_video_path: è¾“å‡ºè§†é¢‘è·¯å¾„
    """
    cap = cv2.VideoCapture(input_video_path)  # æ‰“å¼€è§†é¢‘æ–‡ä»¶
    if not cap.isOpened():
        print(f"âŒ æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {input_video_path}")
        return

    # è·å–è§†é¢‘å±æ€§
    fps = int(cap.get(cv2.CAP_PROP_FPS))  # å¸§ç‡
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))  # è§†é¢‘å®½åº¦
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))  # è§†é¢‘é«˜åº¦

    # é…ç½®è¾“å‡ºè§†é¢‘
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # æŒ‡å®šç¼–ç æ ¼å¼
    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))

    print(f"ğŸ“¹ å¤„ç†è§†é¢‘: {input_video_path} -> {output_video_path}")

    # é€å¸§å¤„ç†è§†é¢‘
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break  # è§†é¢‘ç»“æŸ

        # å¤„ç†å½“å‰å¸§
        processed_frame = process_frame(frame)

        # ä¿å­˜ç»“æœ
        out.write(processed_frame)
        cv2.imshow("Head Pose Estimation", processed_frame)  # æ˜¾ç¤ºå®æ—¶æ£€æµ‹ç»“æœ

        if cv2.waitKey(1) & 0xFF == ord('q'):  # æŒ‰ 'q' é€€å‡º
            break

    # é‡Šæ”¾èµ„æº
    cap.release()
    out.release()
    cv2.destroyAllWindows()
    print(f"âœ… å¤„ç†å®Œæˆï¼Œè§†é¢‘å·²ä¿å­˜: {output_video_path}")


# ç¤ºä¾‹è°ƒç”¨ï¼ˆæ›¿æ¢ä¸ºä½ çš„è§†é¢‘è·¯å¾„ï¼‰
if __name__ == "__main__":
    input_video = "Pre-video1.mp4"  # è¾“å…¥è§†é¢‘è·¯å¾„
    output_video = "output_dlid.mp4"  # è¾“å‡ºè§†é¢‘è·¯å¾„
    generate_video(input_video, output_video)
